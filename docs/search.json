[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Linear Mixed Modelers",
    "section": "",
    "text": "Linear mixed models (LMMs) are statistical models that account for both fixed and random effects. Please follow along as we provide a systematic review of LMMs, their applications, their limitations, and more. Importantly, we will develop a report and by-example analysis of LMMs in R.\nHere’s a snapshot of the analysis process our team is currently going through:\n\nFeel free to meet our team, The Linear Mixed Modelers, on the About tab and review our individual literature contributions on the Literature tab. Our overall report is on the Report tab with code and slides extracted for general use."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Us",
    "section": "",
    "text": "This is the directory for the UWF STA 6257 group: The Linear Mixed Modelers. Thank you for stopping by our page!\n\n\n\n\n\n\n\n\n\nJoshua J. Cook, M.S., ACRP-PM, CCRC\nJoshua J. Cook, M.S., ACRP-PM, CCRC is a recent graduate of Wake Forest University (WFU) where he earned his Master of Science for Clinical Research Management. He is a current graduate student at the University of West Florida (UWF) studying Data Science while working at the university as an Adjunct Professor. Joshua worked in the field of clinical research for nearly three years, starting in neurology clinical trials and then specializing in orthopedic regenerative medicine as a Research Quality Analyst. He has published his undergraduate honors thesis, entitled “Endurance exercise-mediated metabolic reshuffle attenuates high-caloric diet-induced non-alcoholic fatty liver disease” in the Annals of Hepatology and has recently submitted several orthopedic research papers to various journals. He has also presented his research at over ten unique conferences at the local, state, and national levels with topics spanning from the impact of blood sugar on Alzheimer’s Disease to publication metric tracking with R and Microsoft Power BI®. Joshua has developed a passion for bench-to-bedside research and aims to synthesize his knowledge of the biomedical sciences, clinical research, and data science to become a physician-scientist capable of integrating clinical care with clinical research in a way that maximizes evidence-based care options for his patients.\n\n\n\n\n\n\n\n\n\n\n\n\nSyed Ahzaz H. Shah, B.S.\nSyed Ahzaz Shah, a skilled Software Engineer, excels in developing scalable solutions using Python, SQL, Java, and more. Currently working as software engineer, he contributes to API design, debugging, and deployment, showcasing a commitment to engineering best practices. Syed holds a Bachelor’s in Computer Science, complemented by certifications in AWS Cloud Practitioner and Google Data Analytics.\n\n\n\n\n\n\n\n\n\n\n\n\nJacob Hernandez, B.S.\nJacob Hernadnez graduated from the California State University of Long Beach with a degree in Chemical Engineering. Currently, he is Data Analyst for an Aeronautics and Defense Company in California where he uses Python, SQL and Tableau to deliver high quality data products to important stake holders. He has recieved his Google Cloud Data Engineering Certifications and TensorFlow Developer Certification which has helped him produce and deploy machine learning projects for his personal portfolio.\n\n\n\n\n\n\n\n\n\n\n\n\nSara Basili, M.S.\nSara Basili obtained her Master of Science in Computer Science with a concentration in Artificial Intelligence from the University of New Orleans (UNO) in December 2023. She is currently pursuing her Master of Science in Data Science at the University of West Florida (UWF), while working as an AI researcher and directing operations at an Artificial Intelligence company based in New Orleans. Prior to her current roles, she gained over a year of insightful experience working as a Crime Analyst for the District Attorney’s office in New Orleans. Sara earned her B.S. in Statistics from Università degli Studi di Roma “La Sapienza” in March 2021, where she authored a thesis entitled “The Social Impact of Gallup Polls to Measure Public Opinion: An Empirical Analysis of the Knight Communities.” She is proficient in a variety of programming languages, including SQL, R, Python, SAS, and Java, which are central to her work in both artificial intelligence and data science."
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Code",
    "section": "",
    "text": "print(\"TBD\")\n\n[1] \"TBD\""
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Slides",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Report",
    "section": "",
    "text": "Linear mixed-effects models (LMMs) are advanced statistical tools designed to analyze data that exhibit complex structures, such as hierarchical organization, repeated measures, and random effects. These models are particularly useful when data violate the assumptions of traditional ANOVA or regression methods, such as the independence of observations, homoscedasticity, and normality of residuals. LMMs accommodate intra-subject differences, allowing for both fixed effects, which are consistent across individuals, and random effects, which vary among subjects or groups.\nThe implementation of LMMs has been facilitated by various software packages and programming languages. Brown (Brown 2021) provides a comprehensive guide to implementing LMMs in R, a widely used statistical programming language, offering a step-by-step walkthrough of model syntax without delving deeply into complex mathematical foundations. Additionally, the lme4 package, as detailed by Bates et al. (Bates et al. 2015), represents a significant evolution in computational methods for fitting mixed models, offering efficient tools and simplified modeling processes for R users, especially for models with crossed random effects. Pymer4, developed by Jolly (Jolly 2018), bridges R and Python, offering Python users a flexible and integrated tool for linear mixed modeling by leveraging the capabilities of R’s lme4 package. This tool enhances the analytical capabilities within the Python ecosystem, making advanced statistical methods more accessible to a broader audience.\nLMMs find applications across various scientific domains, each with its unique data structures and analytical challenges. The paper by Lee and Shang (Lee and Shang n.d.) explores the impact of missing data on the estimation and selection in LMMs, highlighting the challenges and proposing a method to record missingness using an indicator-based matrix. This approach is critical for ensuring model accuracy in the presence of missing data, a common issue in real-world datasets. Wang et al. (Wang et al. 2022) illustrate the application of LMMs in cardiothoracic surgery outcomes research, using a case study of homograft pulmonary valve replacement data to demonstrate the model’s ability to handle repeated measurements and provide more nuanced understandings of clinical outcomes. Aarts et al (Aarts et al. 2015) demonstrates multilevel design experiments in neuroscience and how using linear models on multilevel data can result in increase in false positives. Magezi (Magezi 2015) highlights the use of LMMs in within-participant psychology experiments, addressing the complexities of repeated measures and nested data structures common in psychological research. Harrison et al. (Harrison et al. 2018) and Bolker et al. (Bolker et al. 2009) discuss the application of LMMs and generalized linear mixed models (GLMMs) in ecology, emphasizing their utility in analyzing ecological data that involve complex relationships and hierarchical data structures with GRU. Grueber et al (GRUEBER et al. 2011) another ecology research, paper focuses on the model averaging and information theorist with LMMS as an alternative to traditional null hypothesis testing. In the medical field, LMMs are employed to model pandemic-induced mortality changes, as demonstrated by Verbeeck et al. (Verbeeck et al. 2023), and to analyze longitudinal health-related quality of life data in cancer clinical trials, as discussed by Touraine et al. (Touraine et al. 2023).\nThe paper “To transform or not to transform: using generalized linear mixed models to analyse reaction time data” by Lo and Andrews (Lo and Andrews 2015) challenges the common practice of transforming reaction time data in cognitive psychology, advocating for GLMMs as a more robust alternative. The “LEVEL” guidelines proposed by Monsalves et al. (Monsalves et al. 2020) aim to standardize the reporting of multilevel data and analyses, enhancing comparability across studies. Piepho’s study (Piepho 1999) on analyzing disease incidence data with GLMMs underscores the inadequacy of traditional methods like ANOVA for such data, highlighting GLMMs’ flexibility. The simulation study by Pusponegoro et al. (Pusponegoro et al. 2017) on children’s growth differences emphasizes the importance of choosing the appropriate covariance structure in LMMs for longitudinal data. Lastly, the framework introduced by Steibel et al. (Steibel et al. 2009) for analyzing RT-PCR data with LMMs showcases the method’s statistical power and flexibility, offering a significant advancement over traditional analysis methods. LMMs are used in a wide array of disciplines, but also in varying study designs, as shown in Table 1.\nTable 1. Systematic Review of LMM Use-cases (Casals et al. 2014)\n\nThe strengths of LMMs lie in their flexibility to model complex data structures and their ability to handle missing data, making them a powerful tool for a wide range of scientific inquiries. However, their application is not without challenges. Peng and Lu (Peng and Lu 2012) address the difficulty of variable selection and parameter estimation in LMMs, proposing an iterative procedure to improve model accuracy. Barr (Barr 2013) critiques existing guidelines for testing interactions within LMMs, proposing new guidelines to ensure more reliable results. The work by Tu (Tu 2015) on GLMMs for network meta-analyses showcases how mixed models have evolved to tackle complex data, enhancing the accuracy of combining different studies. On the other hand, Fokkema et al. (Marjolein Fokkema and Wolpert 2021) introduce GLMM trees, merging machine learning with mixed models to improve predictions and analysis, particularly useful in mental health research. Despite their robustness, as noted by Schielzeth et al. (Schielzeth et al. 2020), LMMs require careful evaluation of model assumptions and may present computational challenges, especially with high-dimensional datasets.\nThe literature reviewed here collectively emphasizes the versatility, robustness, and broad applicability of LMMs and GLMMs across various fields of research. Despite their advantages, the importance of careful model selection, acknowledgment of limitations, and the potential need for more complex models such as joint models in certain scenarios are also highlighted. As the use of LMMs continues to grow, the development of standardized processes, such as the LEVEL framework (Monsalves et al. 2020) and the 10 protocol put forth by (Zuur and Ieno 2016), and user-friendly tools will be crucial in ensuring the accurate and effective application of these models in research."
  },
  {
    "objectID": "literature.html",
    "href": "literature.html",
    "title": "Literature",
    "section": "",
    "text": "What is the goal of the paper?\nThe paper presents the lme4 package for R, which facilitates the fitting of linear mixed-effects models. The authors aim to articulate the package’s capabilities in evaluating the profiled deviance or REML criterion for linear mixed models and to explain the representation and optimization of such models for parameter estimation.\nWhy is it important?\nThe significance of this paper lies in its contribution to the field of computational methods for fitting mixed models—an area with many open problems. The lme4 package represents an evolution in this domain, offering more efficient computational tools and a syntax that simplifies the modeling process, especially for models with crossed random effects.\nHow is it solved? – methods\nThe package utilizes maximum likelihood or restricted maximum likelihood (REML) estimates for linear mixed-effects model parameters, employing numerical representation and optimization functions within R. The paper delves into the model’s structure, the evaluative steps for the profiled deviance or REML criterion, and the class structure representing such models, highlighting the improvements over previous formulations.\nResults/limitations, if any.\nThe document focuses more on methodology than specific results or limitations. It details the improvement over the nlme package, addressing efficient linear algebra tools and the incorporation of profile likelihood confidence intervals on random-effects parameters. The paper emphasizes the ongoing development of the lme4 package, acknowledging the need for stability and usability for a broad range of applications.\n\n\n\nWhat is the goal of the paper?\nThe goal of the paper is to provide a detailed introduction to developing and interpreting linear mixed-effects models for repeated measurements in the context of cardiothoracic surgery outcomes research. The paper uses a dataset on patients undergoing surgical pulmonary valve replacement to illustrate the steps of developing such models for clinician researchers.\nWhy is it important?\nThis work is important because the emergence of large cardio-thoracic surgery datasets, including repeated measurements over time, presents an opportunity to apply advanced modeling of outcomes. Linear mixed-effects models offer a more nuanced understanding of these outcomes compared to traditional methods, which is crucial for enhancing clinical decision-making and patient care.\nHow is it solved? – methods\nThe authors used a retrospective dataset containing serial echocardiographic measurements from patients who underwent surgical pulmonary valve replacement at Erasmus MC between 1986 and 2017. The paper discusses the construction of the model, including dealing with missing values, correlated variables, and multicollinearity. It also covers model specification, variable selection, addressing nonlinearity, and interpretation of results. An R script is provided for implementing the model.\nResults/limitations, if any.\nThe paper illustrates the construction of the model, including essential aspects such as theories of linear mixed-effects models, missing values, collinearity, interaction, nonlinearity, model specification, and results interpretation. It shows that linear mixed-effects models provide a more detailed view of repeated measurements and give more valid estimates compared to linear regression models, especially in the context of cardio-thoracic surgery outcomes research. Limitations related to model assumptions, such as linearity and normal distribution of residuals, are addressed through transformations and statistical tests.\n\n\n\nWhat is the goal of the paper?\nThe goal of this paper is to provide a comprehensive guide on the use and application of Generalized Linear Mixed Models (GLMMs) for ecologists and evolutionary biologists dealing with nonnormal data types, such as counts or proportions, which often do not fit well with classical statistical procedures. The paper aims to clarify the use of GLMMs, given the popularity of these models in recent years.\nWhy is it important?\nThe importance of this paper lies in its attempt to introduce GLMMs for biologists, where data often fall outside the scope of methods taught in introductory statistics classes. The paper highlights the limitations of traditional shortcuts like data transformation or ignoring random effects and advocates for GLMMs as a more appropriate statistical approach for nonnormal data with random effects.\nHow is it solved? – methods\nThe paper reviews the use and misuse of GLMMs in biology, discusses estimation and inference, and summarizes best-practice data analysis procedures. It emphasizes the need for researchers to match their statistical approaches to their data, rather than forcing data into classical statistical frameworks. The paper discusses various estimation algorithms for fitting GLMMs, including maximum likelihood (ML), pseudo- and penalized quasilikelihood (PQL), Laplace approximations, Gauss-Hermite quadrature (GHQ), and Markov chain Monte Carlo (MCMC) algorithms.\nResults/limitations, if any.\nWhile the paper provides a broad overview of GLMM procedures and best practices, it also acknowledges the challenges and controversies in statistical issues such as null hypothesis testing, stepwise regression, and the use of Bayesian statistics. It highlights that GLMMs are powerful tools but can be challenging to use, even for statisticians, due to computational difficulties in estimating parameters, especially for complex models or large numbers of random effects.\n\n\n\nWhat is the goal of the paper?\nThe goal of this paper is to introduce linear mixed-effects models (LMMs) as a versatile tool for analyzing data from within-participant psychology experiments. It seeks to address the limitations of traditional analysis methods like ANOVA in handling complex data structures, such as those involving repeated measures or nested designs. The paper also introduces LMMgui, a free, graphical user interface designed to facilitate the use of LMMs for researchers using R.\nWhy is it important?\nThe importance of this work lies in its potential to enhance the analysis of experimental psychology data by providing a more flexible and robust statistical tool that can handle the complexities of within-participant designs, such as pseudoreplication and missing data. By offering a user-friendly interface for LMM analysis, the paper aims to make advanced statistical methods more accessible to researchers, thereby improving the quality and interpretability of psychological research.\nHow is it solved? – methods\nThe paper discusses the theoretical foundation of LMMs, explaining how they can accommodate various data structures and assumptions that are commonly encountered in psychology experiments. It contrasts LMMs with traditional repeated-measures ANOVA, highlighting the advantages of LMMs in terms of their flexibility and fewer stringent assumptions. The introduction of LMMgui is a significant methodological contribution, providing a step-by-step guide on how to use this tool to specify and compare different LMMs for data analysis.\nResults/limitations, if any.\nWhile the paper primarily serves as a tutorial and does not present results from a specific study, it effectively demonstrates the application of LMMs through hypothetical examples. These examples illustrate how LMMs can be used to analyze data from within-participant designs, accounting for random effects and complex variance-covariance structures. The paper acknowledges the challenges in interpreting LMM results and the potential for increased Type I error rates in certain conditions, emphasizing the need for careful model comparison and validation.\n\n\n\nWhat is the goal of the paper?\nThe goal of this paper is to estimate baseline mortality (mortality under non-pandemic conditions for Belgium and the Netherlands using a linear mixed model (LMM), which can account for both fixed and random effects. If baseline mortality can be modeled, then excess mortality (the measure of the increase in mortality from all causes during a specific time period) can be used to evaluate the impact of COVID-19 on mortality.\nWhy is it important?\nHistorically, 5-year weekly averages have been used to determine baseline mortality. However, this excludes year-specific trends in mortality and the effects of historical excess mortality (ex: past influenza breakouts or heat waves). Using a LMM is important because it allows for more accurate modeling that accounts for these factors in the form of random effects.\nHow is it solved? – methods\nThe paper proposes a general linear mixed model to model weekly mortality as Ytj, with t = 1,…,52 weeks and by year j = 2009…,2020.\nThe model is then adjusted to: model the cyclic pattern from year to year via random effects of Fourier terms, and reduce the influence of historical excess mortality (as mentioned above) by downweighing the residuals.\nResults/limitations, if any.\nSeveral statistics were used to evaluate the model’s forecasting accuracy, including the likelihood ratio test (LRT) and the root mean square error % (RMSE%). The models were fitted to historical mortality year from 2009- week 10 of 2020. The remaining 42 weeks of 2020 were forecasted using the LMM, along with the 5-year average model, and the ground truth data. The models all performed well, so an overall recommendation to include the down-weight procedure for past excess mortality and to include a serial correlation structure were made. The LMM did fit the mortality data better and two years were better predicted compared to the 5-year weekly average models. Many limitations exist, including differences in the reporting of COVID-19 deaths in Belgium and the Netherlands, and across the world. Additionally, it is unclear if the added complexity of LMMs provide a significant benefit over 5-year weekly average models in years besides 2014 and 2016.\n\n\n\nWhat is the goal of the paper?\nThe goal of this paper is to address a potential shortcoming of LMMs, which is when data is not missing at random, but instead, data is missing that is dependent on the health-related quality-of-life of the patient (i.e., data is missing because quality-of-life – the outcome - decreased). Viewing missing data like this, a survival model may be more appropriate. Or, as this paper suggests, a joint model (JM) that includes both LMM and survival sub-models.\nWhy is it important?\nThis concept is important because clinical trials are frequently employing LMMs to evaluate longitudinal data. Clinical trials involve human subjects, which are known to be more variable compared to benchtop studies. This includes variation in the completeness of patient reported outcome measures (PROMs), especially for longitudinal studies. Many times, this variation is random, and independent of the outcome measure. However, if the outcome measure itself is having an effect on the completeness, then it could represent a major bias limitation of LMMs that should be addressed using the proposed joint models.\nHow is it solved? – methods\nThis paper first introduces the LMM that is traditional in longitudinal clinical studies like this. Then, to account for the fact that observations in quality-of-life scores ends with a dropout event, a joint model is created by linking the LMM to a survival model with shared parameters.\nThis JM was then evaluated using historical clinical trial data where a standard LMM was utilized, and in several simulation studies where extreme examples of this dependence was introduced.\nResults/limitations, if any.\nThis paper showed that poor quality-of-life scores are associated with drop out. Therefore, LMMs should be avoided when analyzing this data in clinical trials. The LMMs in both the historical studies and in the simulations were overly optimistic in estimating the quality-of-life scores. Specifically, the LMM overestimates the slope governing the prediction trajectory in both treatment and control arms. The LMM is also more optimistic for the control arm than the experimental arm, despite the protective effect of treatment on the quality-of-life score."
  },
  {
    "objectID": "literature.html#an-introduction-to-linear-mixed-effects-modeling-in-r---violet-a.-brown-2021-uwf.edu",
    "href": "literature.html#an-introduction-to-linear-mixed-effects-modeling-in-r---violet-a.-brown-2021-uwf.edu",
    "title": "Literature",
    "section": "",
    "text": "What is the goal of the paper?\nThe article aims to introduce the utility of linear mixed-effects models (LMMs) over traditional ANOVA or regression methods, emphasizing their applicability in handling intra-subject differences and their flexibility with missing values and outliers. This was specifically done in R.\nWhy is it important?\nLMMs are highlighted for their ability to not assume independence of observations, making them particularly suitable for psychological research where within-subject differences are common.\nHow is it solved? – methods\nThe article employs a psychology-based dataset to demonstrate the implementation of LMMs using R. It focuses on explaining the concepts of fixed effects and random effects in LMMs, providing the data and code for readers to follow along without delving deeply into the mathematical foundations of LMMs.\nResults/limitations, if any.\nThe primary contribution is the detailed walkthrough of LME model syntax in R and interpretation within the context of psychological data. The article suggests that the methods described should be generalizable across various industries, although it is based on a specific psychology dataset."
  },
  {
    "objectID": "literature.html#a-brief-introduction-to-mixed-effects-modelling-and-multi-model-inference-in-ecology---pmc-nih.gov",
    "href": "literature.html#a-brief-introduction-to-mixed-effects-modelling-and-multi-model-inference-in-ecology---pmc-nih.gov",
    "title": "Literature",
    "section": "",
    "text": "What is the goal of the paper?\nThis article aims to demonstrate the application of LMMs and multi-model inference within the field of ecology, focusing on error and model selection using biological data.\nWhy is it important?\nThe significance of the article lies in its broad overview of LMMs in the context of ecological data, addressing the challenges of error and model selection in ecological research.\nHow is it solved? – methods\nThe methodology includes a detailed examination of information theory and multi-model inference, applied to example ecological data. The article provides data and code for replication and further exploration.\nResults/limitations, if any.\nWhile the article offers valuable insights into the use of LMMs in ecology, including data and code for practical application, it primarily serves as an introductory piece, potentially leaving out more advanced aspects of LMMs and multi-model inference."
  },
  {
    "objectID": "literature.html#generalized-linear-mixed-models-a-practical-guide-for-ecology-and-evolution---sciencedirect",
    "href": "literature.html#generalized-linear-mixed-models-a-practical-guide-for-ecology-and-evolution---sciencedirect",
    "title": "Literature",
    "section": "",
    "text": "What is the goal of the paper?\nThe goal of this paper is to provide a comprehensive guide on the use and application of Generalized Linear Mixed Models (GLMMs) for ecologists and evolutionary biologists dealing with nonnormal data types, such as counts or proportions, which often do not fit well with classical statistical procedures. The paper aims to clarify the use of GLMMs, given the popularity of these models in recent years.\nWhy is it important?\nThe importance of this paper lies in its attempt to introduce GLMMs for biologists, where data often fall outside the scope of methods taught in introductory statistics classes. The paper highlights the limitations of traditional shortcuts like data transformation or ignoring random effects and advocates for GLMMs as a more appropriate statistical approach for nonnormal data with random effects.\nHow is it solved? – methods\nThe paper reviews the use and misuse of GLMMs in biology, discusses estimation and inference, and summarizes best-practice data analysis procedures. It emphasizes the need for researchers to match their statistical approaches to their data, rather than forcing data into classical statistical frameworks. The paper discusses various estimation algorithms for fitting GLMMs, including maximum likelihood (ML), pseudo- and penalized quasilikelihood (PQL), Laplace approximations, Gauss-Hermite quadrature (GHQ), and Markov chain Monte Carlo (MCMC) algorithms.\nResults/limitations, if any.\nWhile the paper provides a broad overview of GLMM procedures and best practices, it also acknowledges the challenges and controversies in statistical issues such as null hypothesis testing, stepwise regression, and the use of Bayesian statistics. It highlights that GLMMs are powerful tools but can be challenging to use, even for statisticians, due to computational difficulties in estimating parameters, especially for complex models or large numbers of random effects."
  },
  {
    "objectID": "literature.html#frontiers-linear-mixed-effects-models-for-within-participant-psychology-experiments-an-introductory-tutorial-and-free-graphical-user-interface-lmmgui-frontiersin.org",
    "href": "literature.html#frontiers-linear-mixed-effects-models-for-within-participant-psychology-experiments-an-introductory-tutorial-and-free-graphical-user-interface-lmmgui-frontiersin.org",
    "title": "Literature",
    "section": "",
    "text": "What is the goal of the paper?\nThe goal of this paper is to introduce linear mixed-effects models (LMMs) as a versatile tool for analyzing data from within-participant psychology experiments. It seeks to address the limitations of traditional analysis methods like ANOVA in handling complex data structures, such as those involving repeated measures or nested designs. The paper also introduces LMMgui, a free, graphical user interface designed to facilitate the use of LMMs for researchers using R.\nWhy is it important?\nThe importance of this work lies in its potential to enhance the analysis of experimental psychology data by providing a more flexible and robust statistical tool that can handle the complexities of within-participant designs, such as pseudoreplication and missing data. By offering a user-friendly interface for LMM analysis, the paper aims to make advanced statistical methods more accessible to researchers, thereby improving the quality and interpretability of psychological research.\nHow is it solved? – methods\nThe paper discusses the theoretical foundation of LMMs, explaining how they can accommodate various data structures and assumptions that are commonly encountered in psychology experiments. It contrasts LMMs with traditional repeated-measures ANOVA, highlighting the advantages of LMMs in terms of their flexibility and fewer stringent assumptions. The introduction of LMMgui is a significant methodological contribution, providing a step-by-step guide on how to use this tool to specify and compare different LMMs for data analysis.\nResults/limitations, if any.\nWhile the paper primarily serves as a tutorial and does not present results from a specific study, it effectively demonstrates the application of LMMs through hypothetical examples. These examples illustrate how LMMs can be used to analyze data from within-participant designs, accounting for random effects and complex variance-covariance structures. The paper acknowledges the challenges in interpreting LMM results and the potential for increased Type I error rates in certain conditions, emphasizing the need for careful model comparison and validation."
  },
  {
    "objectID": "literature.html#a-linear-mixed-model-to-estimate-covid-19-induced-excess-mortality---pubmed-nih.gov",
    "href": "literature.html#a-linear-mixed-model-to-estimate-covid-19-induced-excess-mortality---pubmed-nih.gov",
    "title": "Literature",
    "section": "",
    "text": "What is the goal of the paper?\nThe goal of this paper is to estimate baseline mortality (mortality under non-pandemic conditions for Belgium and the Netherlands using a linear mixed model (LMM), which can account for both fixed and random effects. If baseline mortality can be modeled, then excess mortality (the measure of the increase in mortality from all causes during a specific time period) can be used to evaluate the impact of COVID-19 on mortality.\nWhy is it important?\nHistorically, 5-year weekly averages have been used to determine baseline mortality. However, this excludes year-specific trends in mortality and the effects of historical excess mortality (ex: past influenza breakouts or heat waves). Using a LMM is important because it allows for more accurate modeling that accounts for these factors in the form of random effects.\nHow is it solved? – methods\nThe paper proposes a general linear mixed model to model weekly mortality as Ytj, with t = 1,…,52 weeks and by year j = 2009…,2020.\nThe model is then adjusted to: model the cyclic pattern from year to year via random effects of Fourier terms, and reduce the influence of historical excess mortality (as mentioned above) by downweighing the residuals.\nResults/limitations, if any.\nSeveral statistics were used to evaluate the model’s forecasting accuracy, including the likelihood ratio test (LRT) and the root mean square error % (RMSE%). The models were fitted to historical mortality year from 2009- week 10 of 2020. The remaining 42 weeks of 2020 were forecasted using the LMM, along with the 5-year average model, and the ground truth data. The models all performed well, so an overall recommendation to include the down-weight procedure for past excess mortality and to include a serial correlation structure were made. The LMM did fit the mortality data better and two years were better predicted compared to the 5-year weekly average models. Many limitations exist, including differences in the reporting of COVID-19 deaths in Belgium and the Netherlands, and across the world. Additionally, it is unclear if the added complexity of LMMs provide a significant benefit over 5-year weekly average models in years besides 2014 and 2016."
  },
  {
    "objectID": "literature.html#when-a-joint-model-should-be-preferred-over-a-linear-mixed-model-for-analysis-of-longitudinal-health-related-quality-of-life-data-in-cancer-clinical-trials---pubmed-nih.gov",
    "href": "literature.html#when-a-joint-model-should-be-preferred-over-a-linear-mixed-model-for-analysis-of-longitudinal-health-related-quality-of-life-data-in-cancer-clinical-trials---pubmed-nih.gov",
    "title": "Literature",
    "section": "",
    "text": "What is the goal of the paper?\nThe goal of this paper is to address a potential shortcoming of LMMs, which is when data is not missing at random, but instead, data is missing that is dependent on the health-related quality-of-life of the patient (i.e., data is missing because quality-of-life – the outcome - decreased). Viewing missing data like this, a survival model may be more appropriate. Or, as this paper suggests, a joint model (JM) that includes both LMM and survival sub-models.\nWhy is it important?\nThis concept is important because clinical trials are frequently employing LMMs to evaluate longitudinal data. Clinical trials involve human subjects, which are known to be more variable compared to benchtop studies. This includes variation in the completeness of patient reported outcome measures (PROMs), especially for longitudinal studies. Many times, this variation is random, and independent of the outcome measure. However, if the outcome measure itself is having an effect on the completeness, then it could represent a major bias limitation of LMMs that should be addressed using the proposed joint models.\nHow is it solved? – methods\nThis paper first introduces the LMM that is traditional in longitudinal clinical studies like this. Then, to account for the fact that observations in quality-of-life scores ends with a dropout event, a joint model is created by linking the LMM to a survival model with shared parameters.\nThis JM was then evaluated using historical clinical trial data where a standard LMM was utilized, and in several simulation studies where extreme examples of this dependence was introduced.\nResults/limitations, if any.\nThis paper showed that poor quality-of-life scores are associated with drop out. Therefore, LMMs should be avoided when analyzing this data in clinical trials. The LMMs in both the historical studies and in the simulations were overly optimistic in estimating the quality-of-life scores. Specifically, the LMM overestimates the slope governing the prediction trajectory in both treatment and control arms. The LMM is also more optimistic for the control arm than the experimental arm, despite the protective effect of treatment on the quality-of-life score."
  },
  {
    "objectID": "literature.html#introduction-to-linear-mixed-models-oarc.ucla.edua",
    "href": "literature.html#introduction-to-linear-mixed-models-oarc.ucla.edua",
    "title": "Literature",
    "section": "INTRODUCTION TO LINEAR MIXED MODELS (oarc.ucla.edua)",
    "text": "INTRODUCTION TO LINEAR MIXED MODELS (oarc.ucla.edua)\nWhat is the goal of the paper?\nThe goal of the paper is to show how linear mixed models can help analyze data sets with non independence. Non independence can happen when data is hierarchical in structure resulting in correlations within groups in the data sets resulting in the violation of the assumption of independence between observations. The example provided has a sample dataset with different patient observations belonging to multiple doctors.\nWhy is it important?\nGoing on the aforementioned example, data can be averaged on a doctor group level but his would result in less data. And you can not make inferences about an individual patient. You can also do multiple linear models for each doctor but the models themselve have less data resulting in more noise.\nHow is it solved? – methods\nLinear Mixed models find a trade off between both approaches where the random effects are still considered for each doctor but there is still an overall grand or fixed effect.\nResults/limitations, if any.\nThere was no dataset or experiment analyzed in this paper. It is just a technical overview."
  },
  {
    "objectID": "literature.html#linear-mixed-model-for-analyzing-longitudinal-data-a-simulation-study-of-children-growth-differences-sciencedirect.com",
    "href": "literature.html#linear-mixed-model-for-analyzing-longitudinal-data-a-simulation-study-of-children-growth-differences-sciencedirect.com",
    "title": "Literature",
    "section": "Linear Mixed Model for Analyzing Longitudinal Data: A Simulation Study of Children Growth Differences (sciencedirect.com)",
    "text": "Linear Mixed Model for Analyzing Longitudinal Data: A Simulation Study of Children Growth Differences (sciencedirect.com)\nWhat is the goal of the paper?\nThe goal of the paper is to use Linear Mixed Models to analyze multilevel data of developmental growth rates in children. Different covariance structures were modeled within the LMM to capture correlated data through time.\nWhy is it important?\nGrowth curves in children are usually represented as a 2 level data structure. At level 2 is the individual child and at the second level is each individual observation. Traditional linear models are not effective due to the non-independence of the data.\nHow is it solved? – methods\nThe simulation study found that the UN covariance performed the best although it suffered from efficiency because of the high number of parameters leaving the ARH(1) as a solid alternative. The data was also not naturally collected but simulated\nResults/limitations, if any.\nThe simulation study found that the UN covariance performed the best although it suffered from efficiency because of the high number of parameters leaving the ARH(1) as a solid alternative. The data was also not naturally collected but simulated"
  },
  {
    "objectID": "literature.html#a-brief-introduction-to-mixed-effects-modelling-and-multi-model-inference-in-ecology-nih.gov",
    "href": "literature.html#a-brief-introduction-to-mixed-effects-modelling-and-multi-model-inference-in-ecology-nih.gov",
    "title": "Literature",
    "section": "A brief introduction to mixed effects modelling and multi-model inference in ecology (nih.gov)",
    "text": "A brief introduction to mixed effects modelling and multi-model inference in ecology (nih.gov)\nWhat is the goal of the paper?\nThe goal of this paper is to serve as a guide on the end to end to end analysis from formulating a hypothesis to inference to explaining the model parameters as it regards to biological and ecological data. Advantages and disadvantages are discussed with the different options available at different parts of the linear mixed model analysis pipeline\nWhy is it important?\nThis article is relevant to our group especially, to those unfamiliar with Linear Mix Models like myself. As it regards to biological science, this paper helps the reader avoid common pitfalls when implementing LMMs\nHow is it solved? – methods\nThe paper has a play by play on the different stages of LMM analysis with tangible example that include data, code and several graphs.\nResults/limitations, if any\nThere is no study or actual experiment being analyzed by linear mixed models. Although it does have references to plenty of academic research papers"
  },
  {
    "objectID": "literature.html#level-logical-explanations-visualizations-of-estimates-in-linear-mixed-models-recommendations-for-reporting-multilevel-data-and-analyses",
    "href": "literature.html#level-logical-explanations-visualizations-of-estimates-in-linear-mixed-models-recommendations-for-reporting-multilevel-data-and-analyses",
    "title": "Literature",
    "section": "LEVEL (Logical Explanations & Visualizations of Estimates in Linear mixed models): recommendations for reporting multilevel data and analyses",
    "text": "LEVEL (Logical Explanations & Visualizations of Estimates in Linear mixed models): recommendations for reporting multilevel data and analyses\nWhat is the goal of the paper?\nResearchers use LLMs to study hierarchical data and often report them under different names like mixed effects models, multilevel data, contextual analysis and hierarchical studies. There is no standardization across these papers for analyzing hierarchical data which leads to different aspects being reported. The goal of the paper is to make a standardized process for analyzing multilevel data\nWhy is it important?\nThis is important so studies across different time periods can be compared more easily.\nHow is it solved? – methods\nThe paper suggests using the LEVEL (Logical Explanations & Visualizations of Estimates in Linear mixed models) as framework for conducting studies with reporting recommendations\nResults/limitations, if any.\nLack of flexibility. Sticking to a framework can inhibit creative analysis since you’re always looking at the framework for guidance."
  },
  {
    "objectID": "literature.html#estimation-and-selection-in-linear-mixed-models-with-missing-data-under-compound-symmetric-structure-nih.gov",
    "href": "literature.html#estimation-and-selection-in-linear-mixed-models-with-missing-data-under-compound-symmetric-structure-nih.gov",
    "title": "Literature",
    "section": "Estimation and selection in linear mixed models with missing data under compound symmetric structure (nih.gov)",
    "text": "Estimation and selection in linear mixed models with missing data under compound symmetric structure (nih.gov)\nWhat is the goal of the paper?\nMissing values occur all the time in real data. Statisticians and scientists use linear mixed models as a way to circumvent this issue. This paper aims to examine the estimation and model selection performance when faced with different rates of missing data. The paper employs two types of missing data. Missing at random and not at random.\nWhy is it important?\nGiven the frequency of missing data it’s important to know the impact it has on the model’s results. It’s also important to be able to\nHow is it solved? – methods\nMissingness of data is recorded using an indicator based matrix and then a likelihood based estimator is made to capture the probability of distribution of the observed data given the model parameters.\nResults/limitations, if any.\nThere is adequate model performance when there is a moderate amount of missingness in the data. However, the paper focuses on compound symmetric structures which assumes equal variance among any given pair of observations."
  },
  {
    "objectID": "literature.html#when-to-use-mixed-models",
    "href": "literature.html#when-to-use-mixed-models",
    "title": "Literature",
    "section": "When to use mixed models",
    "text": "When to use mixed models\nWhat is the goal of the paper?\nThe goal of the paper is to provide insights into the appropriate usage of mixed models in data science projects. It aims to discuss the types of outcome variables that mixed models can handle, highlight their advantages and disadvantages, and offer guidance on when to use them effectively.\nWhy is it important?\nUnderstanding when to employ mixed models is crucial for data scientists as these models offer unique capabilities, such as handling nested data structures and accommodating multiple readings on the same subject. Utilizing mixed models appropriately can improve the accuracy and interpretability of statistical analyses, especially in scenarios involving complex data structures.\nHow is it solved? – methods\nThe paper discusses the advantages and disadvantages of mixed models, outlining scenarios where they are beneficial and situations where they may not be necessary. It provides examples to illustrate the application of mixed models in scenarios involving hierarchical data structures and multiple measurements on the same subject. Additionally, the paper offers guidance on model selection and references related articles for further exploration.\nResults/limitations, if any.\nThe paper presents several advantages of mixed models, including their ability to handle nested data, provide interpretable coefficients, and accommodate missing measurements."
  },
  {
    "objectID": "literature.html#an-introduction-to-linear-mixed-effects-modeling-in-r",
    "href": "literature.html#an-introduction-to-linear-mixed-effects-modeling-in-r",
    "title": "Literature",
    "section": "An Introduction to Linear Mixed-Effects Modeling in R",
    "text": "An Introduction to Linear Mixed-Effects Modeling in R\nWhat is the goal of the paper?\nThe goal of the tutorial is to provide both theoretical understanding and practical guidance on implementing mixed-effects models in R, particularly for researchers with basic statistical knowledge but limited experience in using these models. It aims to address the limitations of traditional statistical methods like repeated measures ANOVAs in analyzing correlated data and to introduce mixed-effects modeling as a more flexible and appropriate approach.\nWhy is it important?\nUnderstanding mixed-effects modeling is crucial for researchers, especially in fields like experimental psychology where traditional methods may not adequately address the complexities of correlated data. By offering accessible explanations and practical examples, the tutorial aims to empower researchers to effectively analyze their data using mixed-effects models, thereby improving the quality and validity of their research findings.\nHow is it solved? – methods\nThe tutorial provides a theoretical introduction to mixed-effects modeling, explaining concepts such as fixed and random effects in simple terms. It contrasts mixed-effects modeling with traditional methods like repeated measures ANOVAs, highlighting the advantages of the former in handling correlated data and various types of response variables. Practical guidance is offered through R code snippets and example data, allowing readers to follow along and implement mixed-effects models in their own research.\nResults/limitations, if any.\nThe tutorial does not present empirical results but rather serves as an educational resource. It effectively communicates the benefits of mixed-effects modeling and provides step-by-step instructions for implementation in R."
  },
  {
    "objectID": "literature.html#a-brief-introduction-to-mixed-effects-modelling-and-multi-model-inference-in-ecology",
    "href": "literature.html#a-brief-introduction-to-mixed-effects-modelling-and-multi-model-inference-in-ecology",
    "title": "Literature",
    "section": "A brief introduction to mixed effects modelling and multi-model inference in ecology",
    "text": "A brief introduction to mixed effects modelling and multi-model inference in ecology\nWhat is the goal of the paper?\nThe paper aims to provide best practices for applying linear mixed effects models (LMMs) to biological data, particularly in ecology and evolutionary studies. It seeks to address the complexities of ecological data and offer guidance on model selection, interpretation, and common pitfalls encountered during modeling.\nWhy is it important?\nWith the increasing use of LMMs in biological data analysis, particularly in ecology, establishing best practices is critical for enhancing the robustness of conclusions drawn from ecological and evolutionary studies. Effective application of LMMs can improve the accuracy and reliability of research findings.\nHow is it solved? – methods The paper discusses various aspects of applying LMMs to biological data, including model selection, error structure, data transformation, and methods for model selection. It emphasizes the importance of careful consideration and consultation with a statistician, particularly in complex situations.\nResults/limitations, if any\nWhile the paper does not present empirical results, it offers practical solutions and recommendations for researchers working with ecological data. It effectively communicates the advantages and disadvantages of LMMs and provides valuable insights for their application in ecology and evolutionary studies."
  },
  {
    "objectID": "literature.html#introduction-to-linear-mixed-models",
    "href": "literature.html#introduction-to-linear-mixed-models",
    "title": "Literature",
    "section": "INTRODUCTION TO LINEAR MIXED MODELS",
    "text": "INTRODUCTION TO LINEAR MIXED MODELS\nWhat is the goal of the paper?\nThe article aims to provide a step-by-step code implementation guide for Linear Mixed Models (LMMs) and to explain the introduction of random effects in these models.\nWhy is it important?\nUnderstanding random effects in mixed models is crucial for researchers as it allows for the consideration of variability within and between groups in hierarchical data structures. Properly defining and incorporating random effects ensures accurate modeling and interpretation, helping to avoid issues such as pseudoreplication and ensuring the independence of observations.\nHow is it solved? – methods\nThe article explains the concepts of crossed and nested random effects in mixed models. Crossed random effects occur when factors are not hierarchically structured and can be observed across multiple levels, while nested random effects occur when one factor is nested within another, forming a hierarchical structure. The importance of properly coding the data to explicitly define nested structures is emphasized.\nResults/limitations, if any.\nThe article does not present empirical results but serves as an educational resource on implementing LMMs with random effects."
  },
  {
    "objectID": "literature.html#robustness-of-linear-mixed-effects-models-to-violations-of-distributional-assumptions",
    "href": "literature.html#robustness-of-linear-mixed-effects-models-to-violations-of-distributional-assumptions",
    "title": "Literature",
    "section": "Robustness of linear mixed-effects models to violations of distributional assumptions",
    "text": "Robustness of linear mixed-effects models to violations of distributional assumptions\nWhat is the goal of the paper?\nThe paper aims to investigate the robustness of linear mixed-effects models (LMMs) in analyzing complex datasets commonly found in ecology and evolution. It evaluates the impact of various violations of distributional assumptions and missing random effect components on model estimates.\nWhy is it important?\nUnderstanding the robustness of LMMs is crucial for researchers working with complex ecological and evolutionary datasets. Despite potential violations of assumptions and missing components, LMMs are widely used in these fields. Assessing their robustness helps ensure the accuracy and reliability of model estimates, even in challenging scenarios.\nHow is it solved? – methods\nThe study evaluates the impact of skewed, bimodal, and heteroscedastic random effect and residual variances, as well as the effects of missing random effect terms and correlated fixed effect predictors on model estimates. It likely employs simulations or analytical approaches to systematically assess the performance of LMMs under various conditions.\nResults/limitations, if any.\nThe results indicate that while violations of assumptions may lead to slight biases and decreased precision in estimates, the overall robustness of LMMs allows for accurate and unbiased estimation of fixed and random effects."
  },
  {
    "objectID": "literature.html#model-selection-in-linear-mixed-effect-models",
    "href": "literature.html#model-selection-in-linear-mixed-effect-models",
    "title": "Literature",
    "section": "Model selection in linear mixed effect models",
    "text": "Model selection in linear mixed effect models\nWhat is the goal of the paper?\nThe goal of the paper is to improve variable selection and parameter estimation in linear mixed effect models, which are critical for analyzing longitudinal, panel, and cross-sectional data in various scientific domains.\nWhy is it important?\nImproving variable selection and parameter estimation is crucial because it directly impacts the accuracy and reliability of data analysis across scientific fields. Efficiently identifying relevant variables and accurately estimating their effects are essential for drawing valid conclusions from complex data structures.\nHow is it solved? – Methods\nThe authors introduce a simple, iterative procedure that employs the smoothly clipped absolute deviation (SCAD) penalty function to estimate and select both fixed and random effects in these models. This approach is highlighted for being a consistent variable selection method with some oracle properties, suggesting it can perform almost as well as if the true underlying model were known.\nResults/limitations, if any.\nThe approach’s effectiveness and efficiency are validated through simulation studies and real data analysis. Nevertheless, the paper also points out limitations, including the method’s dependence on certain conditions for its asymptotic properties to hold and the potential computational challenges encountered with high-dimensional datasets."
  },
  {
    "objectID": "literature.html#random-effects-structure-for-testing-interactions-in-linear-mixed-effects-models",
    "href": "literature.html#random-effects-structure-for-testing-interactions-in-linear-mixed-effects-models",
    "title": "Literature",
    "section": "Random Effects Structure for Testing Interactions in Linear Mixed-Effects Models",
    "text": "Random Effects Structure for Testing Interactions in Linear Mixed-Effects Models\nWhat is the goal of the paper?\nThe goal is to provide a more accurate method for testing interactions within linear mixed-effects models, critiquing existing guidelines and proposing new ones that emphasize the inclusion of random slopes for the highest-order combination of within-unit factors in interactions.\nWhy is it important?\nThis is important because accurately testing interactions in mixed-effects models is crucial for statistical analyses, especially in avoiding high Type I error rates. The paper aims to refine the approach to these models to ensure more reliable results.\nHow is it solved? – Methods\nThe author employs Monte Carlo simulations to test the proposed guidelines, demonstrating that neglecting critical random slopes can significantly increase the chance of a false rejection of the null hypothesis. Including appropriate random slopes in the model is shown to ensure better performance.\nResults/limitations, if any.\nThe findings highlight that including the correct random slopes in mixed-effects models greatly improves model performance, particularly in accurately testing interactions between categorical variables. However, the paper’s limitations include its focus on interactions between categorical variables and the specific conditions of the simulations used."
  },
  {
    "objectID": "literature.html#pymer4-connecting-r-and-python-for-linear-mixed-modeling",
    "href": "literature.html#pymer4-connecting-r-and-python-for-linear-mixed-modeling",
    "title": "Literature",
    "section": "Pymer4: Connecting R and Python for Linear Mixed Modeling",
    "text": "Pymer4: Connecting R and Python for Linear Mixed Modeling\nWhat is the goal of the paper?\nThe goal is to develop Pymer4, a tool that bridges R and Python for linear mixed modeling, addressing the gap in Python for a package as flexible as R’s lme4 for complex data analysis.\nWhy is it important?\nPymer4 is significant for providing Python users with an accessible, integrated tool for linear mixed modeling, which was previously lacking, enhancing the analytical capabilities within the Python ecosystem.\nHow is it solved? – Methods\nPymer4 offers a solution by by leveraging the rpy2 library, as it connects to R’s lme4 package, offering a Pythonic interface for mixed modeling that integrates well with scientific Python tools, simplifying the analysis process.\nResults/limitations, if any.\nPymer4 successfully extends lme4’s functionality to Python users, offering features like significance testing and data visualization integration, enhancing multilevel model analysis. The paper focuses on the tool’s capabilities without detailing specific limitations."
  },
  {
    "objectID": "literature.html#a-powerful-and-flexible-linear-mixed-model-framework-for-the-analysis-of-relative-quantification-rt-pcr-data",
    "href": "literature.html#a-powerful-and-flexible-linear-mixed-model-framework-for-the-analysis-of-relative-quantification-rt-pcr-data",
    "title": "Literature",
    "section": "A powerful and flexible linear mixed model framework for the analysis of relative quantification RT-PCR data",
    "text": "A powerful and flexible linear mixed model framework for the analysis of relative quantification RT-PCR data\nWhat is the goal of the paper?\nThe paper introduces a novel linear mixed model framework for analyzing relative quantification RT-PCR data, aiming to overcome the limitations of existing statistical methods by providing more accurate and flexible analysis tools.\nWhy is it important?\nThis framework is crucial for its potential to enhance the statistical power and flexibility in analyzing RT-PCR data, enabling researchers to conduct more reliable and varied analyses of gene expression across different experimental conditions.\nHow is it solved? – Methods\nThe method involves a sophisticated statistical approach that incorporates both fixed and random effects in a linear mixed model, allowing for a more nuanced analysis of RT-PCR data that accounts for various sources of variability.\nResults/limitations, if any.\nThe framework has been shown to yield more accurate and statistically powerful results compared to traditional methods, facilitating better decision-making in biological research. The paper thoroughly evaluates the model’s performance and discusses its applicability to a wide range of experimental designs."
  },
  {
    "objectID": "report.html#implementation-methods",
    "href": "report.html#implementation-methods",
    "title": "Report",
    "section": "",
    "text": "The implementation of LMMs has been facilitated by various software packages and programming languages. Brown (Brown 2021) provides a comprehensive guide to implementing LMMs in R, a widely used statistical programming language, offering a step-by-step walkthrough of model syntax without delving deeply into complex mathematical foundations. Additionally, Pymer4, developed by Jolly (Jolly 2018), bridges R and Python, offering Python users a flexible and integrated tool for linear mixed modeling by leveraging the capabilities of R’s lme4 package. This tool enhances the analytical capabilities within the Python ecosystem, making advanced statistical methods more accessible to a broader audience."
  },
  {
    "objectID": "report.html#industry-specific-uses",
    "href": "report.html#industry-specific-uses",
    "title": "Report",
    "section": "",
    "text": "LMMs find applications across various scientific domains, each with its unique data structures and analytical challenges. Magezi (Magezi 2015) highlights the use of LMMs in within-participant psychology experiments, addressing the complexities of repeated measures and nested data structures common in psychological research. Harrison Et. A. (Harrison et al. 2018) and Bolker Et. Al. (Bolker et al. 2009) discuss the application of LMMs and generalized linear mixed models (GLMMs) in ecology, emphasizing their utility in analyzing ecological data that involve complex relationships and hierarchical data structures. In the medical field, LMMs are employed to model pandemic-induced mortality changes, as demonstrated by Verbeeck Et. Al. (Verbeeck et al. 2023), and to analyze longitudinal health-related quality of life data in cancer clinical trials, as discussed by Touraine Et. Al. [Touraine et al. (2023)]."
  },
  {
    "objectID": "report.html#strengths-and-weaknesses",
    "href": "report.html#strengths-and-weaknesses",
    "title": "Report",
    "section": "",
    "text": "The strengths of LMMs lie in their flexibility to model complex data structures and their ability to handle missing data, making them a powerful tool for a wide range of scientific inquiries. However, their application is not without challenges. Peng and Lu (Peng and Lu 2012) address the difficulty of variable selection and parameter estimation in LMMs, proposing an iterative procedure to improve model accuracy. Barr (Barr 2013) critiques existing guidelines for testing interactions within LMMs, proposing new guidelines to ensure more reliable results. Despite their robustness, as noted by Schielzeth Et. Al. [Schielzeth et al. (2020)], LMMs require careful evaluation of model assumptions and may present computational challenges, especially with high-dimensional datasets."
  },
  {
    "objectID": "report.html#purpose",
    "href": "report.html#purpose",
    "title": "Report",
    "section": "",
    "text": "This literature review collectively emphasize the versatility, robustness, and broad applicability of LMMs and GLMMs across various fields of research. Despite their advantages, the importance of careful model selection, acknowledgment of limitations, and the potential need for more complex models such as joint models in certain scenarios are also highlighted. As the use of LMMs continues to grow, the development of standardized processes and user-friendly tools will be crucial in ensuring the accurate and effective application of these models in research."
  },
  {
    "objectID": "literature.html#to-transform-or-not-to-transform-using-generalized-linear-mixed-models-to-analyse-reaction-time-data",
    "href": "literature.html#to-transform-or-not-to-transform-using-generalized-linear-mixed-models-to-analyse-reaction-time-data",
    "title": "Literature",
    "section": "To transform or not to transform: using generalized linear mixed models to analyse reaction time data",
    "text": "To transform or not to transform: using generalized linear mixed models to analyse reaction time data\nWhat is the goal of the paper?\nThe paper aims to challenge the common practice of transforming reaction time (RT) data to meet normality assumptions in statistical analyses within cognitive psychology research. It proposes generalized linear mixed-effect models (GLMMs) as a solution to accurately analyze RT data without the need for transformation, thus avoiding potential theoretical implications and misleading conclusions.\nWhy is it important?\nIt highlights the discrepancy between analyses of raw RT data and transformed RT data, as demonstrated by Balota et al. (2013), emphasizing the need for a more nuanced approach to analyzing RT data. By advocating for GLMMs, the paper aims to promote proper assessment of individual differences and enhance the testing of cognitive theories.\nHow is it solved? – Methods\nThe study discusses the theoretical decisions involved in specifying a GLMM and provides reanalysis of datasets from Balota et al. (2013) to illustrate the application of GLMMs in RT data analysis. It emphasizes the importance of analyzing changes in RT distribution at a finer level to capture more accurate measures of group performance and effectively test cognitive theories.\nResults/limitations, if any.\nThe paper suggests that GLMMs offer a more robust approach to analyzing RT data compared to traditional methods like linear mixed-effect models (LMMs) with transformed data. However, it acknowledges the complexities of addressing skewed dependent variables like RT in LMMs and the potential challenges in adopting GLMMs, such as the need for careful model specification."
  },
  {
    "objectID": "literature.html#analysing-disease-incidence-data-from-designed-experiments-by-generalized-linear-mixed-models",
    "href": "literature.html#analysing-disease-incidence-data-from-designed-experiments-by-generalized-linear-mixed-models",
    "title": "Literature",
    "section": "Analysing disease incidence data from designed experiments by generalized linear mixed models",
    "text": "Analysing disease incidence data from designed experiments by generalized linear mixed models\nWhat is the goal of the paper?\nThe paper aims to introduce generalized linear mixed models (GLMMs) as a robust method for analyzing disease incidence data from designed experiments, specifically addressing overdispersion issues common in epidemiological research.\nWhy is it important?\nIt highlights the inadequacy of traditional methods like ANOVA for such data, underlining the need for alternative approaches like GLMMs to better capture the complexities of disease clustering and aggregation.\nHow is it solved? – Methods\nThe study presents GLMMs as a versatile tool, capable of accommodating both fixed and random effects, thus offering a more flexible framework for analyzing disease incidence data. It illustrates the application of GLMMs using real-world data from an experiment on downy mildew incidence in grapevines.\nResults/limitations, if any.\nThe analysis using GLMMs reveals significant treatment effects and provides parameter estimates. However, the approach is not without limitations, including assumptions made in modeling and the potential challenge of interpreting results accurately, particularly in complex experimental designs."
  },
  {
    "objectID": "literature.html#fitting-linear-mixed-effects-models-using-lme4-journal-of-statistical-software-jstatsoft.org",
    "href": "literature.html#fitting-linear-mixed-effects-models-using-lme4-journal-of-statistical-software-jstatsoft.org",
    "title": "Literature",
    "section": "",
    "text": "What is the goal of the paper?\nThe paper presents the lme4 package for R, which facilitates the fitting of linear mixed-effects models. The authors aim to articulate the package’s capabilities in evaluating the profiled deviance or REML criterion for linear mixed models and to explain the representation and optimization of such models for parameter estimation.\nWhy is it important?\nThe significance of this paper lies in its contribution to the field of computational methods for fitting mixed models—an area with many open problems. The lme4 package represents an evolution in this domain, offering more efficient computational tools and a syntax that simplifies the modeling process, especially for models with crossed random effects.\nHow is it solved? – methods\nThe package utilizes maximum likelihood or restricted maximum likelihood (REML) estimates for linear mixed-effects model parameters, employing numerical representation and optimization functions within R. The paper delves into the model’s structure, the evaluative steps for the profiled deviance or REML criterion, and the class structure representing such models, highlighting the improvements over previous formulations.\nResults/limitations, if any.\nThe document focuses more on methodology than specific results or limitations. It details the improvement over the nlme package, addressing efficient linear algebra tools and the incorporation of profile likelihood confidence intervals on random-effects parameters. The paper emphasizes the ongoing development of the lme4 package, acknowledging the need for stability and usability for a broad range of applications."
  },
  {
    "objectID": "literature.html#statistical-primer-an-introduction-to-the-application-of-linear-mixed-effects-models-in-cardiothoracic-surgery-outcomes-research-a-case-study-using-homograft-pulmonary-valve-replacement-data---pubmed-nih.gov",
    "href": "literature.html#statistical-primer-an-introduction-to-the-application-of-linear-mixed-effects-models-in-cardiothoracic-surgery-outcomes-research-a-case-study-using-homograft-pulmonary-valve-replacement-data---pubmed-nih.gov",
    "title": "Literature",
    "section": "",
    "text": "What is the goal of the paper?\nThe goal of the paper is to provide a detailed introduction to developing and interpreting linear mixed-effects models for repeated measurements in the context of cardiothoracic surgery outcomes research. The paper uses a dataset on patients undergoing surgical pulmonary valve replacement to illustrate the steps of developing such models for clinician researchers.\nWhy is it important?\nThis work is important because the emergence of large cardio-thoracic surgery datasets, including repeated measurements over time, presents an opportunity to apply advanced modeling of outcomes. Linear mixed-effects models offer a more nuanced understanding of these outcomes compared to traditional methods, which is crucial for enhancing clinical decision-making and patient care.\nHow is it solved? – methods\nThe authors used a retrospective dataset containing serial echocardiographic measurements from patients who underwent surgical pulmonary valve replacement at Erasmus MC between 1986 and 2017. The paper discusses the construction of the model, including dealing with missing values, correlated variables, and multicollinearity. It also covers model specification, variable selection, addressing nonlinearity, and interpretation of results. An R script is provided for implementing the model.\nResults/limitations, if any.\nThe paper illustrates the construction of the model, including essential aspects such as theories of linear mixed-effects models, missing values, collinearity, interaction, nonlinearity, model specification, and results interpretation. It shows that linear mixed-effects models provide a more detailed view of repeated measurements and give more valid estimates compared to linear regression models, especially in the context of cardio-thoracic surgery outcomes research. Limitations related to model assumptions, such as linearity and normal distribution of residuals, are addressed through transformations and statistical tests."
  },
  {
    "objectID": "report.html#mathematical-foundations",
    "href": "report.html#mathematical-foundations",
    "title": "Report",
    "section": "2.1 Mathematical Foundations",
    "text": "2.1 Mathematical Foundations\nLMMs have a mathematical foundation stemming from linear algebra. We will be using notation for a 2-level longitudinal model since that is the structure of the dataset in this report. The index i is used to denote participants and t is used to denote the different time points of the observations. Given this notation t is the first level and i is the second level.\nSimple LMMs can be defined as in Equation 1.\n\\[\ny=X\\beta + Zu+ \\epsilon\n\\tag{1}\\]\nwhere:\n\nY is the response vector.\nX is the design matrix for fixed effects.\nβ is the vector of fixed effects (parameters associated with the entire population or certain repeatable levels of experimental factors).\nZ is the design matrix for random effects.\nu is the vector of random effects (represent random deviations from the population parameters (β ) for different subjects or experimental units; i.e., the variability not explained by the fixed effects).\nϵ is the vector of residual errors.\n\nMatrix and Vector Dimensions (Random Intercepts)\n\nY is N x 1 matrix where N is the number of the number of repeated measures\nX is a N x p matrix where p is the number of fixed effects covariates\nβ is p x 1 column vector\nZ is a N x J matrix where J number of subjects\nu is J x 1 vector\nϵ is n x 1 vector\n\nFor a model with a random intercept, the first column of the X matrix will be all 1s and the first element in the β vector will pertain to that random intercept. The Z matrix in a random intercepts model is a block diagonal matrix, with the block defined by Zi matrices.\nAdding random effects to the model also changes the size of the dimensions of the Z. If one random effect is added to the matrix then the dimensions change to N x 2q which essentially doubles the columns of the Z matrix to account for the random intercept. u will also double in length to be 2q x 1.\n\n2.1.1 Example\nNow let’s go over an example with a 2-level longitudinal structure where we have 100 students with 10 test scores per student and the associated study time for those tests. In this case, the dependent variable is the variable concerning test scores, the fixed effect is the study time and the random effect is the student. For the sake of simplicity, we will only consider a random intercepts model.\nVariable Breakdown:\n\nN=1000: the number of observations which is the number of students multiplied by  the number of test scores \nJ = 10: the number of students \np = 2: the random intercept and the fixed effect \n\nMatrix Notations and Dimension laid out:\n\\(Y_{1000\\times1} = X_{1000\\times 2} \\; \\beta_{2\\times1} + Z_{1000\\times10}\\;u_{10\\times1} + \\epsilon_{1000\\times1}\\)\nExample Matrices:\n\\(y = \\begin{bmatrix} Score\\\\ 75 \\\\ 80\\\\ ... \\\\ 90 \\end{bmatrix} X = \\begin{bmatrix} Intercept & Study Time \\\\1 & 2 \\\\1 & 3\\\\... & ... \\\\1 & 5\\end{bmatrix}\\)\n\\(\\beta = \\begin{bmatrix} 1.2\\\\2.3\\end{bmatrix}\\)\nThe matrix multiplication can also be broken down into individual equations. In the case of our example we get the following equations:\nLevel 1 (Time):\n\\(Y_{ti} = \\beta_{0j} + \\beta_{1j} \\cdot \\text{StudyTime}_{ti} + e_{ti}\\)\nLevel 2 (Student):\n\\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\nSince this is a random intercepts model, only the intercept equation is needed. γ00 is the grand intercept mean an u0j is the deviation of the jth group, which in our case is the student. (Galecki 2014).\n\n\n2.1.1 Parameter Estimation\nLMMs typically use a Maximum Likelihood estimation or variation called Restricted Maximum likelihood Estimation (REML). Both of these methods obtain parameters of β and θ by optimizing the likelihood function. β are the fixed effects parameters and θ are the covariance matrix parameters where θ depends on the number of random effects and the covariance matrix structure. Our model uses the REML method because it is less biased to the covariance parameters and better at modeling random effects (Galecki 2014)."
  },
  {
    "objectID": "report.html#breakdown-of-mathematical-foundations",
    "href": "report.html#breakdown-of-mathematical-foundations",
    "title": "Report",
    "section": "2.2 Breakdown of Mathematical Foundations",
    "text": "2.2 Breakdown of Mathematical Foundations\n[PLACEHOLDER FOR LAYMANS TERMS EXPLANATIONS]"
  },
  {
    "objectID": "report.html#sample-data-structure",
    "href": "report.html#sample-data-structure",
    "title": "Report",
    "section": "2.3 Sample Data Structure",
    "text": "2.3 Sample Data Structure\nLMMs require a tidy data set where each variables are columns and observations are rows. Smaller datasets are usually saved as CSV files and are often loaded from a database. The dataset can contain nulls but they still need to be handled whether they are omitted or imputed and depends on the amount and which columns are affected. The lmer() function in the lme4 library will automatically drop any null values so it is important that data is inspected and visualized before constructing any models. Below is an example of tidy data.\n\n\n\nFigure 1. Tidy data, as defined by Wickham Et. Al.\n\n\nLMMs also require that the structure of both random and fixed effects be defined before the model is created. The variables that have random variation across groups and those that are fixed must be identified. There are different hierarchies in LMMs. First of all we have to distinguish between clustered and longitudinal data. With cluttered data, as the name suggests, groups the subjects or the unit of analysis into different groups. For a two level data set we can have students be the unit of analysis and the next level up is the classrooms. For a three level data set we can add schools as the third level. Regardless of the amount of levels, the first level is always the subject of the unit of analysis, In the example mentioned above, its students (Galecki 2014).\nThen there is also longitudinal data where repeated measures are at the first level and the unit of analysis is the second level. A dataset with different patient cholesterol data over time has the measures at different timepoints as the first level and the patients at a second level (Galecki 2014)."
  },
  {
    "objectID": "report.html#packages",
    "href": "report.html#packages",
    "title": "Report",
    "section": "3.1 Packages",
    "text": "3.1 Packages\n\n\nCode\nif (!requireNamespace(c(\"tidyverse\", \"lme4\", \"nlme\", \"Matrix\", \"gt\", \"RefManageR\", \"DataExplorer\", \"gtsummary\", \"car\"), quietly = TRUE)) {\n    install.packages(c(\"tidyverse\", \"lme4\", \"nlme\", \"Matrix\", \"gt\", \"RefManageR\", \"DataExplorer\", \"gtsummary\", \"car\"))\n}\n\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(nlme)\nlibrary(gt)\nlibrary(gtsummary)\nlibrary(RefManageR)\nlibrary(DataExplorer)\nlibrary(Matrix)\nlibrary(car)\nlibrary(reshape2)\n\n#references &lt;- ReadBib(\"references.bib\")\n#summary(references)\n\n\n\ntidyverse: used for data wrangling and visualization.\nlme4 and nlme: used for LMM within R.\nMatrix: used for matrix manipulation.\ngt: used for table generation.\ngtsummary: used for summary table generation of descriptive statistics.\nRefManageR: used for BibTex reference management.\nDataExplorer: used for EDA.\nMatrix: used for sparse and dense matrix classes and methods.\ncar: for qq plots.\nreshape2: to reshape date.\n\n\n\n\n\n\n\nAn error was encountered with the Matrix and lme4 packages during model creation. If this error is encountered, please:\n\n\n\n\nremove.packages(“Matrix”)\n\n\nremove.packages(“lme4”)\n\n\ninstall.packages(“lme4”, type = “source”)\n\n\nlibrary(lme4)"
  },
  {
    "objectID": "report.html#data-ingestion",
    "href": "report.html#data-ingestion",
    "title": "Report",
    "section": "3.2 Data Ingestion",
    "text": "3.2 Data Ingestion\n\n\nCode\n# Load the dataset\nBMI &lt;- read.csv(\"data/BMI_IOS_SCD_Asthma.csv\")\n\ncolnames(BMI) &lt;- c(\"Group\", \"Subject_ID\", \"Observation_number\", \"Hydroxyurea\", \"Asthma\", \"ICS\", \"LABA\", \"Gender\", \"Age_months\", \"Height_cm\", \"Weight_Kg\", \"BMI\", \"R5Hz_PP\", \"R20Hz_PP\", \"X5Hz_PP\", \"Fres_PP\")\n\nBMI$Group &lt;- as.factor(BMI$Group)\nBMI$Subject_ID &lt;- as.factor(BMI$Subject_ID)\nBMI$Observation_number &lt;- as.factor(BMI$Observation_number)\n\n\n\nBMI from Kaggle (Impact of BMI on IOS measures on children (kaggle.com))\n\nDescription: This dataset is from a retrospective study to assess the impact of BMI on impulse oscillometry (IOS) estimates of airway resistance and reactance in children with sickle cell disease (C-SCD).\nDetailed Description: The dataset comprises various attributes and measurements across its columns. Categorical variables, such as Group, Subject ID, Observation_number, Hydroxyurea, Asthma, ICS, LABA, and Gender, denote different groupings, individual subjects, and attributes like medication usage and gender. Numerical variables like Age (months), Height (cm), Weight (Kg), BMI, R5Hz_PP, R20Hz_PP, X5Hz_PP, and Fres_PP provide quantitative data on subjects’ characteristics and test results. Notably, the summary also identifies missing values, such as the 14 instances in the Fres_PP variable, which warrant consideration in subsequent analysis. These columns provide measurements and estimates related to airway resistance and reactance obtained using impulse oscillometry (IOS), which is a non-invasive method for assessing respiratory function. These parameters are valuable in understanding the impact of BMI on respiratory measures in children with sickle cell disease (C-SCD) and African-American children with asthma (C-Asthma) participating in the study.\nWhy suitable for LMMs: The dataset has multiple observations, over time, for the same set of participants."
  },
  {
    "objectID": "report.html#exploratory-data-analysis-eda",
    "href": "report.html#exploratory-data-analysis-eda",
    "title": "Report",
    "section": "3.2 Exploratory Data Analysis (EDA)",
    "text": "3.2 Exploratory Data Analysis (EDA)\nThe structure of the dataframe and variable descriptions are shown in Table 2 and Figure 2. Figures 3-10 systematically explore the features of the data and are described below.\n\n\nCode\nx &lt;- BMI\n\nstr(x)\n\n\n'data.frame':   219 obs. of  16 variables:\n $ Group             : Factor w/ 2 levels \"C-Asthma\",\"C-SCD\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Subject_ID        : Factor w/ 90 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 1 1 2 3 3 4 4 5 ...\n $ Observation_number: Factor w/ 6 levels \"1\",\"2\",\"3\",\"4\",..: 1 2 3 4 1 1 2 1 2 1 ...\n $ Hydroxyurea       : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Asthma            : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ ICS               : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ LABA              : chr  \"No\" \"No\" \"Yes\" \"Yes\" ...\n $ Gender            : chr  \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ Age_months        : int  239 193 212 224 204 178 186 222 210 196 ...\n $ Height_cm         : num  164 163 164 164 154 ...\n $ Weight_Kg         : num  61.5 62.3 63.1 63.7 66.4 51.9 56.7 66.7 66.9 52.9 ...\n $ BMI               : num  22.8 23.5 23.6 23.7 27.8 ...\n $ R5Hz_PP           : int  145 103 107 87 124 109 117 101 179 136 ...\n $ R20Hz_PP          : int  133 98 98 87 121 86 105 132 153 97 ...\n $ X5Hz_PP           : num  -456 111 174 -303 98 115 107 -216 195 140 ...\n $ Fres_PP           : int  NA 169 159 NA 135 148 159 NA 175 199 ...\n\n\nCode\nhead(x)\n\n\n  Group Subject_ID Observation_number Hydroxyurea Asthma ICS LABA Gender\n1 C-SCD          1                  1         Yes    Yes Yes   No   Male\n2 C-SCD          1                  2         Yes    Yes Yes   No   Male\n3 C-SCD          1                  3         Yes    Yes Yes  Yes   Male\n4 C-SCD          1                  4         Yes    Yes Yes  Yes   Male\n5 C-SCD          2                  1          No     No  No   No Female\n6 C-SCD          3                  1         Yes    Yes  No   No   Male\n  Age_months Height_cm Weight_Kg   BMI R5Hz_PP R20Hz_PP X5Hz_PP Fres_PP\n1        239     164.1      61.5 22.84     145      133    -456      NA\n2        193     162.7      62.3 23.53     103       98     111     169\n3        212     163.5      63.1 23.60     107       98     174     159\n4        224     163.8      63.7 23.74      87       87    -303      NA\n5        204     154.5      66.4 27.82     124      121      98     135\n6        178     158.0      51.9 20.79     109       86     115     148\n\n\nCode\nvariables &lt;- colnames(x)\n\nvariables_table &lt;- data.frame(\n  Variable = variables,\n  Description = c(\n    \"This column indicates the group to which the subject belongs. There are two groups in the study: children with sickle cell disease (C-SCD) and African-American children with asthma (C-Asthma).\",\n    \"Each subject in the study is assigned a unique identifier or ID, which is listed in this column. The ID is used to differentiate between individual participants.\",\n    \"This column represents the number assigned to each observation or measurement taken for a particular subject. Since this is a longitudinal study, multiple observations may be recorded for each subject over time.\",\n    \"This column indicates whether the subject with sickle cell disease (C-SCD) received hydroxyurea treatment. Hydroxyurea is a medication commonly used for the treatment of sickle cell disease.\",\n    \"This column indicates whether the subject has a diagnosis of asthma. It distinguishes between children with sickle cell disease (C-SCD) and African-American children with asthma (C-Asthma).\",\n    \"This column indicates whether the subject is using inhaled corticosteroids (ICS). ICS is a type of medication commonly used for the treatment of asthma and certain other respiratory conditions.\",\n    \"This column indicates whether the subject is using a long-acting beta-agonist (LABA). LABA is a type of medication often used in combination with inhaled corticosteroids for the treatment of asthma.\",\n    \"This column represents the gender of the subject, indicating whether they are male or female\",\n    \"This column specifies the age of the subject at the time of the observation or measurement. Age is typically measured in months.\",\n    \"This column represents the height of the subject, typically measured in a standard unit of length, such as centimeters or inches. Height is an important variable to consider in assessing the impact of BMI on respiratory measures.\",\n    \"This column indicates the weight of the subject at the time of the observation or measurement. Weight is typically measured in kilograms (Kg) and is an important variable for calculating the body mass index (BMI).\",\n    \"Body Mass Index (BMI) is a measure that assesses body weight relative to height. It is calculated by dividing the weight of an individual (in kilograms) by the square of their height (in meters). The BMI column provides the calculated BMI value for each subject based on their weight and height measurements. BMI is commonly used as an indicator of overall body fatness and is often used to classify individuals into different weight categories (e.g., underweight, normal weight, overweight, obese).\",\n    \"This column represents the estimate of airway resistance at 5 Hz using impulse oscillometry (IOS). Airway resistance is a measure of the impedance encountered by airflow during respiration. The R5Hz_PP value indicates the airway resistance at the frequency of 5 Hz and is obtained through the IOS testing.\",\n    \"This column represents the estimate of airway resistance at 20 Hz using impulse oscillometry (IOS). Similar to R5Hz_PP, R20Hz_PP provides the measure of airway resistance at the frequency of 20 Hz based on the IOS testing.\",\n    \"This column represents the estimate of airway reactance at 5 Hz using impulse oscillometry (IOS). Airway reactance is a measure of the elasticity and stiffness of the airway walls. The X5Hz_PP value indicates the airway reactance at the frequency of 5 Hz and is obtained through the IOS testing.\",\n    \"This column represents the estimate of resonant frequency using impulse oscillometry (IOS). Resonant frequency is a measure of the point at which the reactance of the airways transitions from positive to negative during respiration. The Fres_PP value indicates the resonant frequency and is obtained through the IOS testing.:\"\n    )\n)\n\nvariables_table %&gt;%\n  gt %&gt;%\n  tab_header(\n    title = \"Table 2. Variable Description\"\n  ) %&gt;%\n  tab_footnote(\n    footnote = \"Each variable in the dataset, accompanied by a qualitative description from the study team.\"\n  )\n\n\n\n\n\n\n  \n    \n      Table 2. Variable Description\n    \n    \n    \n      Variable\n      Description\n    \n  \n  \n    Group\nThis column indicates the group to which the subject belongs. There are two groups in the study: children with sickle cell disease (C-SCD) and African-American children with asthma (C-Asthma).\n    Subject_ID\nEach subject in the study is assigned a unique identifier or ID, which is listed in this column. The ID is used to differentiate between individual participants.\n    Observation_number\nThis column represents the number assigned to each observation or measurement taken for a particular subject. Since this is a longitudinal study, multiple observations may be recorded for each subject over time.\n    Hydroxyurea\nThis column indicates whether the subject with sickle cell disease (C-SCD) received hydroxyurea treatment. Hydroxyurea is a medication commonly used for the treatment of sickle cell disease.\n    Asthma\nThis column indicates whether the subject has a diagnosis of asthma. It distinguishes between children with sickle cell disease (C-SCD) and African-American children with asthma (C-Asthma).\n    ICS\nThis column indicates whether the subject is using inhaled corticosteroids (ICS). ICS is a type of medication commonly used for the treatment of asthma and certain other respiratory conditions.\n    LABA\nThis column indicates whether the subject is using a long-acting beta-agonist (LABA). LABA is a type of medication often used in combination with inhaled corticosteroids for the treatment of asthma.\n    Gender\nThis column represents the gender of the subject, indicating whether they are male or female\n    Age_months\nThis column specifies the age of the subject at the time of the observation or measurement. Age is typically measured in months.\n    Height_cm\nThis column represents the height of the subject, typically measured in a standard unit of length, such as centimeters or inches. Height is an important variable to consider in assessing the impact of BMI on respiratory measures.\n    Weight_Kg\nThis column indicates the weight of the subject at the time of the observation or measurement. Weight is typically measured in kilograms (Kg) and is an important variable for calculating the body mass index (BMI).\n    BMI\nBody Mass Index (BMI) is a measure that assesses body weight relative to height. It is calculated by dividing the weight of an individual (in kilograms) by the square of their height (in meters). The BMI column provides the calculated BMI value for each subject based on their weight and height measurements. BMI is commonly used as an indicator of overall body fatness and is often used to classify individuals into different weight categories (e.g., underweight, normal weight, overweight, obese).\n    R5Hz_PP\nThis column represents the estimate of airway resistance at 5 Hz using impulse oscillometry (IOS). Airway resistance is a measure of the impedance encountered by airflow during respiration. The R5Hz_PP value indicates the airway resistance at the frequency of 5 Hz and is obtained through the IOS testing.\n    R20Hz_PP\nThis column represents the estimate of airway resistance at 20 Hz using impulse oscillometry (IOS). Similar to R5Hz_PP, R20Hz_PP provides the measure of airway resistance at the frequency of 20 Hz based on the IOS testing.\n    X5Hz_PP\nThis column represents the estimate of airway reactance at 5 Hz using impulse oscillometry (IOS). Airway reactance is a measure of the elasticity and stiffness of the airway walls. The X5Hz_PP value indicates the airway reactance at the frequency of 5 Hz and is obtained through the IOS testing.\n    Fres_PP\nThis column represents the estimate of resonant frequency using impulse oscillometry (IOS). Resonant frequency is a measure of the point at which the reactance of the airways transitions from positive to negative during respiration. The Fres_PP value indicates the resonant frequency and is obtained through the IOS testing.:\n  \n  \n  \n    \n       Each variable in the dataset, accompanied by a qualitative description from the study team.\n    \n  \n\n\n\n\nCode\nplot_str(x)\nintroduce(x)\n\n\n  rows columns discrete_columns continuous_columns all_missing_columns\n1  219      16                8                  8                   0\n  total_missing_values complete_rows total_observations memory_usage\n1                   14           205               3504        34032\n\n\nCode\nplot_intro(x, title=\"Figure 2. Structure of variables and missing observations.\")\n\n\n\n\n\n\n3.2.1 Missing Values\n\n\nCode\nplot_missing(x, title=\"Figure 3. Breakdown of missing observations.\")\n\n\n\n\n\nBased on the missing values count in Figure 3, it appears that there are no missing values in most of the columns, except for Fres_PP, where there are 14 missing values (6.39%). In this case, omitting missing values for Fres_PP is reasonable, considering the small proportion of missing data compared to the total number of observations.\n\n\n3.2.2 Cleaning Data\n\n\nCode\ndim(x)\n\n\n[1] 219  16\n\n\nCode\nx_clean &lt;- na.omit(x) # drops NAs, further analysis is without NA values\nx_clean$Gender &lt;- tolower(x_clean$Gender)\ndim(x_clean)\n\n\n[1] 205  16\n\n\nCode\nstr(x_clean)\n\n\n'data.frame':   205 obs. of  16 variables:\n $ Group             : Factor w/ 2 levels \"C-Asthma\",\"C-SCD\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Subject_ID        : Factor w/ 90 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 2 3 3 4 5 6 6 7 ...\n $ Observation_number: Factor w/ 6 levels \"1\",\"2\",\"3\",\"4\",..: 2 3 1 1 2 2 1 1 2 1 ...\n $ Hydroxyurea       : chr  \"Yes\" \"Yes\" \"No\" \"Yes\" ...\n $ Asthma            : chr  \"Yes\" \"Yes\" \"No\" \"Yes\" ...\n $ ICS               : chr  \"Yes\" \"Yes\" \"No\" \"No\" ...\n $ LABA              : chr  \"No\" \"Yes\" \"No\" \"No\" ...\n $ Gender            : chr  \"male\" \"male\" \"female\" \"male\" ...\n $ Age_months        : int  193 212 204 178 186 210 196 175 200 173 ...\n $ Height_cm         : num  163 164 154 158 164 ...\n $ Weight_Kg         : num  62.3 63.1 66.4 51.9 56.7 66.9 52.9 39 50.6 56.3 ...\n $ BMI               : num  23.5 23.6 27.8 20.8 20.9 ...\n $ R5Hz_PP           : int  103 107 124 109 117 179 136 96 123 117 ...\n $ R20Hz_PP          : int  98 98 121 86 105 153 97 109 115 117 ...\n $ X5Hz_PP           : num  111 174 98 115 107 195 140 111 164 92 ...\n $ Fres_PP           : int  169 159 135 148 159 175 199 104 109 152 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:14] 1 4 8 13 18 21 44 46 50 52 ...\n  ..- attr(*, \"names\")= chr [1:14] \"1\" \"4\" \"8\" \"13\" ...\n\n\nCount Plots for Categorical Variable\nThe bar plots in Figure 4 show frequency distributions for categories within a distribution. This can aid in data cleaning, checking sparseness or checking for class imbalances. It appears that:\n\nMost cases are C-SCD compared to C-Asthma (class imbalance).\nThe number of observations decreases at subsequent measurements.\nMost cases have Asthma (class imbalance).\nMost cases have LABA (class imbalance).\nHydroxyurea, ICS, and Gender are relatively evenly distributed.\n\n\n\nCode\nplot_bar(x_clean, title = \"Figure 4. Frequency plots of categorical variables.\")\n\n\n\n\n\nHistograms\nHistograms in Figure 5 show the frequency and distributions of numerical variables This helps identify distribution types among the different variables. Most of the variables below exhibit a normal distribution with some (BMI) showing a slight right skew.\n\n\nCode\nplot_histogram(x_clean, title = \"Figure 5. Histogram plots of numerical variables.\")\n\n\n\n\n\nQ-Q Plots\nThe QQ plots in Figure 6 serve as a visual aid to asses normality in the covariates. The closer the points are to the straight diagonal line, the more “normal” the data is distributed. Most of the variables show a normal distribution. BMI has a substantial amount of points on the right corner of the plot that go off of the diagonal line potentially representing a non-normal distribution. Weight_Kg shows a similar skew.\n\n\nCode\nplot_qq(na.omit(x), title = \"Figure 6. QQ plots to assess normality of numerical variables.\")\n\n\n\n\n\nPrincipal Component Analysis (PCA)\nThe PCA plots in Figure 7 show the numerical variables in our data set split into principal components. More than half (54.8%) of the variance can be explained with just 4 principal components. This can be useful if we want to simplify our model by only keeping the principal components that explain most of the variance.\n\n\nCode\nplot_prcomp(na.omit(x), title = \"Figure 7. PCA to assess key principle components that explain the variance.\")\n\n\n\n\n\n\n\n\nBox Plots\nBased on the boxplots in Figure 8, it’s evident that all variables except “Age (months)” and “Height (cm)” contain outliers. Now, let’s pinpoint these outliers and calculate summary statistics (Table 3).\nFigure 8. Boxplots of numerical variables.\n\n\nCode\nnumeric_vars &lt;- x_clean %&gt;% \n  select_if(is.numeric)\n\n# Boxplot for each numeric variable\npar(mfrow=c(2, 2))\nfor (col in colnames(numeric_vars)) {\n  boxplot(numeric_vars[[col]], main=col)\n}\n\n\n\n\n\n\n\n\nCode\n# Adding a general title for the entire set of boxplots\n#mtext(\"Figure 8. Box plots of numerical variables.\", side=3, line=1, outer=TRUE, cex=1.5)\n\n\n\n\nCode\n# Define a function to detect outliers in each column\ndetect_outliers &lt;- function(column) {\n  Q1 &lt;- quantile(column, 0.25)\n  Q3 &lt;- quantile(column, 0.75)\n  IQR &lt;- Q3 - Q1\n  lower_bound &lt;- Q1 - 1.5 * IQR\n  upper_bound &lt;- Q3 + 1.5 * IQR\n  outliers &lt;- column[column &lt; lower_bound | column &gt; upper_bound]\n  return(outliers)\n}\n\n# Iterate over each column and print outliers; not removed\nfor (col in names(numeric_vars)) {\n  outliers &lt;- detect_outliers(numeric_vars[[col]])\n  if (length(outliers) &gt; 0) {\n    cat(\"Outliers in\", col, \":\\n\")\n    print(outliers)\n    cat(\"\\n\")\n  }\n}\n\n\nOutliers in Weight_Kg :\n [1]  91.4 100.2 104.4 111.2 120.4 108.6 105.1 100.0  95.5 130.1 108.5 124.6\n[13]  95.2\n\nOutliers in BMI :\n [1] 27.82 37.85 41.49 42.09 26.65 28.66 41.85 41.18 39.89 40.05 38.58 38.74\n[13] 29.92 47.21 41.34 48.07 27.82 26.95\n\nOutliers in R5Hz_PP :\n[1] 187 183 196  10 199 198\n\nOutliers in R20Hz_PP :\n[1] 153 150  12 162 153\n\nOutliers in X5Hz_PP :\n [1]  439 1117  260  270  297  465  338  285  306  -68  543  381\n\n\nCode\nx_clean %&gt;% \n  select(-2) %&gt;%\n  tbl_summary( #gtSummary Table\n    by=Group,\n    type = list(\n      c('Age_months', 'Height_cm', 'Weight_Kg', 'BMI', 'R5Hz_PP', 'R20Hz_PP', 'X5Hz_PP', 'Fres_PP') ~ 'continuous2'),\n    statistic = all_continuous2() ~ c(\n                       \"{mean} ± {sd}\",\n                       \"{median} ({p25}, {p75})\",\n                       \"{min}, {max}\"\n                       ),\n    digits = all_continuous2() ~ 2,\n    missing=\"ifany\",\n  ) %&gt;%\n  bold_labels %&gt;%\n  italicize_levels() %&gt;%\n  as_gt() %&gt;%\n  tab_header(\n    title = \"Table. 3 Summary Statistics\"\n  ) %&gt;%\n  tab_footnote(\n    footnote = \"Summary statistics for all variables.\"\n  )\n\n\n\n\n\n\n  \n    \n      Table. 3 Summary Statistics\n    \n    \n    \n      Characteristic\n      C-Asthma, N = 561\n      C-SCD, N = 1491\n    \n  \n  \n    Observation_number\n\n\n        1\n34 (61%)\n51 (34%)\n        2\n13 (23%)\n44 (30%)\n        3\n7 (13%)\n31 (21%)\n        4\n2 (3.6%)\n17 (11%)\n        5\n0 (0%)\n5 (3.4%)\n        6\n0 (0%)\n1 (0.7%)\n    Hydroxyurea\n0 (0%)\n112 (75%)\n    Asthma\n56 (100%)\n106 (71%)\n    ICS\n40 (71%)\n73 (49%)\n    LABA\n24 (43%)\n14 (9.4%)\n    Gender\n\n\n        female\n22 (39%)\n59 (40%)\n        male\n34 (61%)\n90 (60%)\n    Age_months\n\n\n        Mean ± SD\n132.98 ± 35.59\n142.16 ± 44.70\n        Median (IQR)\n134.00 (100.00, 147.25)\n144.00 (105.00, 179.00)\n        Range\n87.00, 213.00\n50.00, 215.00\n    Height_cm\n\n\n        Mean ± SD\n146.57 ± 17.33\n145.00 ± 18.83\n        Median (IQR)\n144.50 (131.00, 162.00)\n146.20 (132.00, 160.30)\n        Range\n120.00, 185.00\n101.80, 178.90\n    Weight_Kg\n\n\n        Mean ± SD\n52.98 ± 30.88\n40.11 ± 16.06\n        Median (IQR)\n38.30 (30.60, 66.83)\n36.70 (28.30, 51.90)\n        Range\n19.60, 130.10\n14.90, 104.40\n    BMI\n\n\n        Mean ± SD\n23.02 ± 9.17\n18.32 ± 4.10\n        Median (IQR)\n18.38 (17.17, 25.66)\n17.59 (15.87, 19.48)\n        Range\n14.10, 48.07\n13.70, 42.09\n    R5Hz_PP\n\n\n        Mean ± SD\n89.57 ± 25.09\n107.67 ± 32.83\n        Median (IQR)\n85.50 (72.75, 104.50)\n105.00 (85.00, 125.00)\n        Range\n43.00, 168.00\n10.00, 199.00\n    R20Hz_PP\n\n\n        Mean ± SD\n77.16 ± 21.70\n88.77 ± 24.61\n        Median (IQR)\n72.00 (62.00, 88.25)\n88.00 (72.00, 102.00)\n        Range\n38.00, 135.00\n12.00, 162.00\n    X5Hz_PP\n\n\n        Mean ± SD\n101.87 ± 51.52\n138.04 ± 115.20\n        Median (IQR)\n96.00 (74.75, 117.75)\n116.00 (83.00, 157.00)\n        Range\n1.69, 381.00\n-68.00, 1,117.00\n    Fres_PP\n\n\n        Mean ± SD\n120.55 ± 31.25\n136.75 ± 33.35\n        Median (IQR)\n111.50 (99.00, 142.50)\n132.00 (110.00, 163.00)\n        Range\n61.00, 236.00\n66.00, 225.00\n  \n  \n  \n    \n       Summary statistics for all variables.\n    \n    \n      1 n (%)\n    \n  \n\n\n\n\nParticipant Dropout\nFigure 9 and Table 4 show how many subjects had data at each subsequent timepoint, which suggests that this study experienced significant participant dropout over time. This dropout may or may not be attributed to the study itself and should be investigated further. A strength of LMM is that it can handle unbalanced groups (i.e., patients), so we will continue with modeling regardless.\n\n\nCode\nx_clean_timepoints &lt;- x_clean %&gt;%\n  group_by(Observation_number) %&gt;%\n  summarise(Unique_Subjects = n_distinct(Subject_ID))\n\nx_clean_timepoints$Unique_Subjects &lt;- as.numeric(x_clean_timepoints$Unique_Subjects)\n\nggplot(x_clean_timepoints, aes(x = Observation_number, y = Unique_Subjects)) +\n  geom_point(size = 3, color = \"blue\") + # Add points for each observation\n  geom_line(aes(group = 1), color = \"blue\") + # Connect the points with a line\n  theme_minimal() +\n  labs(title = \"Figure 9. Participant dropout over time.\",\n       x = \"Timepoint\",\n       y = \"Number of Unique Subjects\")\n\n\n\n\n\nCode\nx_clean_timepoints %&gt;% \n  gt() %&gt;%\n  tab_header(\n    title = \"Table 4. Number of participants at each timepoint.\"\n  ) %&gt;%\n  tab_footnote(\n    footnote = \"Counts of unique subjects reveal an increasing amount of missing data at subsequent observation visits.\"\n  )\n\n\n\n\n\n\n  \n    \n      Table 4. Number of participants at each timepoint.\n    \n    \n    \n      Observation_number\n      Unique_Subjects\n    \n  \n  \n    1\n85\n    2\n57\n    3\n38\n    4\n19\n    5\n5\n    6\n1\n  \n  \n  \n    \n       Counts of unique subjects reveal an increasing amount of missing data at subsequent observation visits.\n    \n  \n\n\n\n\n\n\n3.2.3 Correlations\nFigure 10 highlights correlations between variables that should be assessed before any modeling. Age (months) and Height (cm): There is a strong positive correlation (0.914) between Age (months) and Height (cm). This implies that as age increases, height tends to increase as well. This correlation is expected, as children tend to grow taller as they get older.\nWeight (Kg) and BMI: There is a strong positive correlation (0.927) between Weight (Kg) and BMI. This suggests that as weight increases, BMI (Body Mass Index) tends to increase as well. This correlation is expected because BMI is calculated using weight and height measurements.\nR5Hz_PP and Fres_PP: There is a strong positive correlation (0.754) between R5Hz_PP and Fres_PP.\n\n\nCode\nplot_correlation(na.omit(x), maxcat=5L, title = \"Figure 10. Correlation matrix of all variables.\")\n\n\n\n\n\nCode\ncorrelation_matrix &lt;- cor(numeric_vars)\nprint(correlation_matrix)\n\n\n           Age_months Height_cm Weight_Kg           BMI      R5Hz_PP   R20Hz_PP\nAge_months  1.0000000 0.9136787 0.6972936  4.441633e-01 4.038596e-01 0.33200111\nHeight_cm   0.9136787 1.0000000 0.7478733  4.581481e-01 3.100369e-01 0.24291582\nWeight_Kg   0.6972936 0.7478733 1.0000000  9.265856e-01 1.261621e-01 0.10391395\nBMI         0.4441633 0.4581481 0.9265856  1.000000e+00 6.430664e-06 0.01337894\nR5Hz_PP     0.4038596 0.3100369 0.1261621  6.430664e-06 1.000000e+00 0.70961067\nR20Hz_PP    0.3320011 0.2429158 0.1039139  1.337894e-02 7.096107e-01 1.00000000\nX5Hz_PP     0.3885715 0.3745554 0.1346387 -2.990486e-02 4.464806e-01 0.20055148\nFres_PP     0.5876287 0.5214880 0.1975967 -1.523383e-02 7.538067e-01 0.54826299\n               X5Hz_PP     Fres_PP\nAge_months  0.38857148  0.58762865\nHeight_cm   0.37455537  0.52148796\nWeight_Kg   0.13463870  0.19759669\nBMI        -0.02990486 -0.01523383\nR5Hz_PP     0.44648059  0.75380665\nR20Hz_PP    0.20055148  0.54826299\nX5Hz_PP     1.00000000  0.50290470\nFres_PP     0.50290470  1.00000000"
  },
  {
    "objectID": "report.html#linear-mixed-modeling",
    "href": "report.html#linear-mixed-modeling",
    "title": "Report",
    "section": "3.3 Linear Mixed Modeling",
    "text": "3.3 Linear Mixed Modeling\nIn this dataset, the variable of interest is body mass index (BMI). Additionally, controlled variables are present such as group, age, weight, height, and other co-morbidities. These are the fixed effects. On the other hand, random variability may exist between individual observations which are nested in each subject. These represent the random effects, as shown in Table 5. In the initial model, Subject_ID was treated as the sole random effect. In the final model, both random effects were incorporated (Subject_ID, Observation_Number).\n\n\nCode\nvariables_table2 &lt;- variables_table %&gt;%\n  select(1) %&gt;%\n  mutate(Type = c(\n    \"Fixed\",\n    \"Random\",\n    \"Random\",\n    \"Fixed\",\n    \"Fixed\",\n    \"Fixed\",\n    \"Fixed\",\n    \"Fixed\",\n    \"Fixed\",\n    \"Fixed\",\n    \"Fixed\",\n    \"Fixed\",\n    \"Fixed\",\n    \"Fixed\",\n    \"Fixed\",\n    \"Fixed\"\n  )\n  )\n\nvariables_table2 %&gt;%\n  gt %&gt;%\n  tab_header(\n    title = \"Table 5. Variable Categorization\"\n  ) %&gt;%\n  tab_footnote(\n    footnote = \"A break down of random and fixed effects based on the purpose of the study. Variable categorization is a crucial step in the LMM process.\"\n  )\n\n\n\n\n\n\n  \n    \n      Table 5. Variable Categorization\n    \n    \n    \n      Variable\n      Type\n    \n  \n  \n    Group\nFixed\n    Subject_ID\nRandom\n    Observation_number\nRandom\n    Hydroxyurea\nFixed\n    Asthma\nFixed\n    ICS\nFixed\n    LABA\nFixed\n    Gender\nFixed\n    Age_months\nFixed\n    Height_cm\nFixed\n    Weight_Kg\nFixed\n    BMI\nFixed\n    R5Hz_PP\nFixed\n    R20Hz_PP\nFixed\n    X5Hz_PP\nFixed\n    Fres_PP\nFixed\n  \n  \n  \n    \n       A break down of random and fixed effects based on the purpose of the study. Variable categorization is a crucial step in the LMM process.\n    \n  \n\n\n\n\n\n\nCode\n#lme()\n\n# Fit models using a tidy and clear approach\nmodel_lme &lt;- lme(\n  fixed = cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP) ~ BMI + Asthma + ICS + LABA + Gender + Age_months + Height_cm + Weight_Kg,\n  random = list(Subject_ID = pdIdent(~1)),\n  data = x_clean,\n  method = \"REML\"\n)\n\n#lmer() \n\nmodel_lmer &lt;- lmer(\n  formula = R5Hz_PP + R20Hz_PP + X5Hz_PP + Fres_PP ~ BMI + Asthma + ICS + LABA + Gender + Age_months + Height_cm + Weight_Kg + (1 | Subject_ID),\n  data = x_clean\n)\n\n\n\n3.3.1 Initial Model\n{.lightbox}\n\n\nCode\n# Compare models based on AIC\naic_lme &lt;- AIC(model_lme)\naic_lmer &lt;- AIC(model_lmer)\n\ncat(sprintf(\"AIC for lme model: %f\\n\", aic_lme))\n\n\nAIC for lme model: 1898.947925\n\n\nCode\ncat(sprintf(\"AIC for lmer model: %f\\n\", aic_lmer))\n\n\nAIC for lmer model: 2517.366883\n\n\nCode\n# Correctly assign final_model based on AIC comparison\nif (aic_lme &lt; aic_lmer) {\n  final_model &lt;- model_lme\n  model_type &lt;- \"lme\"\n} else {\n  final_model &lt;- model_lmer\n  model_type &lt;- \"lmer\"\n}\ncat(sprintf(\"Final model selected: %s\\n\", model_type))\n\n\nFinal model selected: lme\n\n\nCode\n# Since final_model is now correctly assigned, we can call summary on it\nsummary(final_model)\n\n\nLinear mixed-effects model fit by REML\n  Data: x_clean \n       AIC      BIC   logLik\n  1898.948 1935.007 -938.474\n\nRandom effects:\n Formula: ~1 | Subject_ID\n        (Intercept) Residual\nStdDev:    20.45438 19.76739\n\nFixed effects:  cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP) ~ BMI + Asthma + ICS +      LABA + Gender + Age_months + Height_cm + Weight_Kg \n                Value Std.Error  DF   t-value p-value\n(Intercept) 219.89254  86.92600 111  2.529652  0.0128\nBMI          -5.89676   2.67942 111 -2.200760  0.0298\nAsthmaYes    16.70033   7.68459  85  2.173222  0.0325\nICSYes       -4.93413   4.87163 111 -1.012829  0.3133\nLABAYes      -4.35652   6.08228 111 -0.716266  0.4753\nGendermale   -5.68900   5.71803  85 -0.994924  0.3226\nAge_months    0.49796   0.13627 111  3.654089  0.0004\nHeight_cm    -1.04120   0.60384 111 -1.724307  0.0874\nWeight_Kg     1.65586   1.01041 111  1.638803  0.1041\n Correlation: \n           (Intr) BMI    AsthmY ICSYes LABAYs Gndrml Ag_mnt Hght_c\nBMI        -0.927                                                 \nAsthmaYes  -0.135  0.054                                          \nICSYes      0.115 -0.074 -0.378                                   \nLABAYes    -0.011  0.026 -0.055 -0.298                            \nGendermale -0.146  0.146 -0.009 -0.070  0.037                     \nAge_months  0.329 -0.101  0.049 -0.002  0.029  0.146              \nHeight_cm  -0.965  0.830  0.074 -0.110  0.002  0.050 -0.535       \nWeight_Kg   0.938 -0.986 -0.082  0.087 -0.030 -0.122  0.087 -0.852\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.8899150 -0.4840091 -0.1223361  0.4272442  2.5859874 \n\nNumber of Observations: 205\nNumber of Groups: 88 \n\n\nAkaike Information Criterion (AIC)\nThe AIC for both models was calculated. The AIC is a measure of the relative quality of statistical models for a given set of data. Lower AIC values indicate a model that better fits the data without unnecessary complexity.\nHere, the AIC for lme was 1898.95 while lmer was 2517.37.\nThe model with the lower AIC was selected as the final model (lme) despite performance improvements offered by the lme4 package. All additional models were lme.\nResiduals\nResidual plots (Residuals vs. Fitted Values) were created for the lme model to assess the goodness of fit in Figure 11. A horizontal line at y=0 was added as a reference. These plots help in identifying non-linearity, unequal variances, and outliers.\nBased on the residual plot, the model has an ideal random pattern of scattered values with a few possible outliers.\n\n\nCode\n# Residuals\nresiduals_final &lt;- resid(final_model)\n\n# Calculate fitted values and residuals from the final model\nfitted_values &lt;- fitted(final_model)\nresidual_values &lt;- residuals(final_model)\n\n# Create a data frame explicitly for plotting\nplot_data &lt;- data.frame(Fitted = fitted_values, Residuals = residual_values)\n\n# Plotting using ggplot2 for a more flexible and powerful approach\n# Residuals vs Fitted Values\nggplot(plot_data, aes(x = Fitted, y = Residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, color = \"red\") +\n  labs(x = \"Fitted Values\", y = \"Residuals\", title = \"Figure 11. Residuals vs. Fitted Values\")\n\n\n\n\n\nHistogram of Residuals and QQ Plots\nA histogram and a Q-Q (Quantile-Quantile) plot of the residuals were used to check the normality assumption of the residuals (Figure 12). Finally, a QQ plot with a QQ line was produced for a graphical normality check (Figure 13).\nBased on the histogram, the model visually had an ideal bell-shaped curve that resembles the normal distribution. Based on the QQ plot, the model graphically may have had some residuals that were not normally distributed toward the ends.\n\n\nCode\n# Histogram of Residuals\nggplot(plot_data, aes(x = Residuals)) +\n  geom_histogram(binwidth = 1, fill = \"blue\", color = \"black\") +\n  labs(title = \"Figure 12. Histogram of Residuals\")\n\n\n\n\n\nCode\n# Q-Q Plot\nqqPlot(residuals_final, main = \"Figure 13. Q-Q Plot of Residuals\")\n\n\n\n\n\n 35  40 \n 95 113 \n\n\n\n\nCode\n# Shapiro-Wilk Normality Test\nshapiro_test_results &lt;- shapiro.test(residuals_final)\nprint(shapiro_test_results)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals_final\nW = 0.95883, p-value = 1.163e-05\n\n\nThe Shapiro-Wilk test was conducted on the residuals to formally test for normality.\n\\(H_o\\): the residuals are normally distributed.\n\\(H_a\\): the residuals are not normally distributed.\n\\(\\alpha\\) = 0.05\nIn this case, P = 0.00001163. P &lt; 0.05, so the null hypothesis was rejected, suggesting that the residuals were not normally distributed. This model does not satisfy the assumptions of LMMs.\n\n\n3.3.2 Imputed Model\nOutliers (as mentioned above) were present in most variables, and the residuals of the initial model were not normally distributed. To improve model performance, outliers were imputed using the the threshold values. The model was then regenerated and assessed using the same metrics as above (Figures 14-17).\nFigure 14. Box plots of numerical variables.\n\n\nCode\n# Copy the original dataset\nx_clean_imputed &lt;- x_clean\n\n# Define a function for Winsorization\nwinsorize &lt;- function(x, lower_percentile = 0.10, upper_percentile = 0.90) {\n  lower_threshold &lt;- quantile(x, lower_percentile)\n  upper_threshold &lt;- quantile(x, upper_percentile)\n  x[x &lt; lower_threshold] &lt;- lower_threshold\n  x[x &gt; upper_threshold] &lt;- upper_threshold\n  \n  return(x)\n}\n\n# Apply imputation across numeric variables in the copied dataset\nnumeric_vars &lt;- names(x_clean_imputed %&gt;% select_if(is.numeric))\nfor (col in numeric_vars) {\n  x_clean_imputed[[col]] &lt;- winsorize(x_clean_imputed[[col]])\n}\n\n# Visualization with ggplot2\n# Plot boxplots for each numeric variable after imputation\nfor (col in numeric_vars) {\n  p &lt;- ggplot(data = x_clean_imputed, aes(x = \"\", y = !!sym(col))) +\n    geom_boxplot(fill = \"skyblue\", color = \"blue\") +\n    labs(title = paste(\"Boxplot of\", col), x = \"\", y = col)\n  print(p)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Adding a general title for the entire set of boxplots\n#mtext(\"Figure 14. Box plots of numerical variables.\", side=3, line=1, outer=TRUE, cex=1.5)\n\n# Modeling with Imputed Data\n# Refit the model using the lme function with the cleaned data\nmodel_lme_imputed &lt;- lme(fixed = cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP) ~ BMI + Asthma + ICS + LABA + Gender + Age_months + Height_cm + Weight_Kg,\n                       random = list(Subject_ID = pdIdent(~1)),\n                       data = x_clean_imputed,\n                       method = \"REML\")\n\naic_lme_imputed &lt;- AIC(model_lme_imputed)\n\ncat(sprintf(\"AIC for lme model: %f\\n\", aic_lme_imputed))\n\n\nAIC for lme model: 1790.908121\n\n\nCode\n# Extract residuals\nresiduals_imputed &lt;- resid(model_lme_imputed)\n\n# Residuals vs Fitted Values Plot\nggplot(data = data.frame(Fitted = fitted(model_lme_imputed), Residuals = residuals_imputed), aes(x = Fitted, y = Residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, color = \"red\") +\n  labs(x = \"Fitted Values\", y = \"Residuals\", title = \"Figure 15. Residuals vs. Fitted Values\")\n\n\n\n\n\nCode\n# Histogram of Residuals\nggplot(data = data.frame(Residuals = residuals_imputed), aes(x = Residuals)) +\n  geom_histogram(binwidth = 1, fill = \"blue\", color = \"black\") +\n  labs(title = \"Figure 16. Histogram of Residuals\")\n\n\n\n\n\nCode\nqqPlot(residuals_imputed, main = \"Figure 17. Q-Q Plot of Residuals\")\n\n\n\n\n\n17 29 \n39 72 \n\n\nCode\n# Q-Q Plot and Shapiro-Wilk Test\nshapiro_test_results &lt;- shapiro.test(residuals_imputed)\nprint(shapiro_test_results)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals_imputed\nW = 0.98664, p-value = 0.05066\n\n\nThe AIC was calculated as 1790.91, an improvement on the initial model.\nThe Shapiro-Wilk test was conducted on the residuals to formally test for normality.\n\\(H_o\\): the residuals are normally distributed.\n\\(H_a\\): the residuals are not normally distributed.\n\\(\\alpha\\) = 0.05\nIn this case, P = 0.05066. P &gt;0.05, so we failed to reject the null hypothesis, suggesting that the residuals were normally distributed after threshold imputation. This model now satisfies the assumptions of LMMs.\n\n\n3.3.3 Final Model\nThis was a longitudinal study involving multiple observations for each subject over time, and subjects are grouped into two categories (children with sickle cell disease and African-American children with asthma). Thus, in this final model, we modeled Group as a fixed effect since we were interested in the effect of the group itself on the outcome. Subject_ID should be a random effect to account for the repeated measures within subjects, and Observation_number was included as a random slope within Subject_ID (i.e., nested within Subject_ID). The same visualizations and tests were completed to assess the LMM assumptions (Figures 18-20). The residuals show a random pattern (Figure 18), the histogram is approximately normal (Figure 19), and the qq plot follows a straight line (Figure 20), indicating normality.\n\n\nCode\nmodel_lme_imputed_final &lt;- lme(fixed = cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP) ~ BMI + Asthma + ICS + LABA + Gender + Age_months + Height_cm + Weight_Kg + Group,\n                         data = x_clean_imputed,\n                         random = list(Subject_ID = pdIdent(~1 + Observation_number)),\n                         method = \"REML\")\nstr(model_lme_imputed_final)\n\n\nList of 18\n $ modelStruct :List of 1\n  ..$ reStruct:List of 1\n  .. ..$ Subject_ID:'pdIdent' with matrix num [1:6, 1:6] 1.99 0 0 0 0 ...\n  .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. ..$ : chr [1:6] \"(Intercept)\" \"Observation_number2\" \"Observation_number3\" \"Observation_number4\" ...\n  .. .. .. ..$ : chr [1:6] \"(Intercept)\" \"Observation_number2\" \"Observation_number3\" \"Observation_number4\" ...\n  .. ..- attr(*, \"settings\")= int [1:4] 1 1 0 2\n  .. ..- attr(*, \"class\")= chr \"reStruct\"\n  .. ..- attr(*, \"plen\")= Named int 1\n  .. .. ..- attr(*, \"names\")= chr \"Subject_ID\"\n  ..- attr(*, \"settings\")= num [1:4] 1 0 1 2\n  ..- attr(*, \"class\")= chr [1:3] \"lmeStructInt\" \"lmeStruct\" \"modelStruct\"\n  ..- attr(*, \"pmap\")= logi [1, 1] TRUE\n  .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. ..$ : NULL\n  .. .. ..$ : chr \"reStruct\"\n  ..- attr(*, \"fixedSigma\")= logi FALSE\n $ dims        :List of 5\n  ..$ N    : int 205\n  ..$ Q    : int 1\n  ..$ qvec : Named num [1:3] 6 0 0\n  .. ..- attr(*, \"names\")= chr [1:3] \"Subject_ID\" \"\" \"\"\n  ..$ ngrps: Named int [1:3] 88 1 1\n  .. ..- attr(*, \"names\")= chr [1:3] \"Subject_ID\" \"X\" \"y\"\n  ..$ ncol : Named num [1:3] 6 10 1\n  .. ..- attr(*, \"names\")= chr [1:3] \"Subject_ID\" \"\" \"\"\n $ contrasts   :List of 2\n  ..$ Observation_number: num [1:6, 1:5] 0 1 0 0 0 0 0 0 1 0 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. ..$ : chr [1:6] \"1\" \"2\" \"3\" \"4\" ...\n  .. .. ..$ : chr [1:5] \"2\" \"3\" \"4\" \"5\" ...\n  ..$ Group             : num [1:2, 1] 0 1\n  .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. ..$ : chr [1:2] \"C-Asthma\" \"C-SCD\"\n  .. .. ..$ : chr \"C-SCD\"\n $ coefficients:List of 2\n  ..$ fixed : Named num [1:10] 154.99 -3.77 15.54 -3.26 -3.16 ...\n  .. ..- attr(*, \"names\")= chr [1:10] \"(Intercept)\" \"BMI\" \"AsthmaYes\" \"ICSYes\" ...\n  ..$ random:List of 1\n  .. ..$ Subject_ID: num [1:88, 1:6] -3.56 8.76 -1.48 13.86 8.56 ...\n  .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. ..$ : chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n  .. .. .. ..$ : chr [1:6] \"(Intercept)\" \"Observation_number2\" \"Observation_number3\" \"Observation_number4\" ...\n $ varFix      : num [1:10, 1:10] 4621.9 -125.4 -56.5 29.6 -33.7 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:10] \"(Intercept)\" \"BMI\" \"AsthmaYes\" \"ICSYes\" ...\n  .. ..$ : chr [1:10] \"(Intercept)\" \"BMI\" \"AsthmaYes\" \"ICSYes\" ...\n $ sigma       : num 11\n $ apVar       : num [1:2, 1:2] 0.0107 -0.0118 -0.0118 0.0277\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2] \"reStruct.Subject_ID\" \"lSigma\"\n  .. ..$ : chr [1:2] \"reStruct.Subject_ID\" \"lSigma\"\n  ..- attr(*, \"Pars\")= Named num [1:2] 2.74 2.4\n  .. ..- attr(*, \"names\")= chr [1:2] \"reStruct.Subject_ID\" \"lSigma\"\n  ..- attr(*, \"natural\")= logi TRUE\n $ logLik      : num -889\n $ numIter     : NULL\n $ groups      :'data.frame':   205 obs. of  1 variable:\n  ..$ Subject_ID: Factor w/ 88 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 2 3 3 4 5 6 6 7 ...\n $ call        : language lme.formula(fixed = cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP) ~ BMI +      Asthma + ICS + LABA + Gender + Age_mo| __truncated__ ...\n $ terms       :Classes 'terms', 'formula'  language cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP) ~ BMI + Asthma + ICS + LABA +      Gender + Age_months + Height_cm + W| __truncated__\n  .. ..- attr(*, \"variables\")= language list(cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP), BMI, Asthma, ICS, LABA,      Gender, Age_months, Height_cm, Weight_Kg, Group)\n  .. ..- attr(*, \"factors\")= int [1:10, 1:9] 0 1 0 0 0 0 0 0 0 0 ...\n  .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. ..$ : chr [1:10] \"cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP)\" \"BMI\" \"Asthma\" \"ICS\" ...\n  .. .. .. ..$ : chr [1:9] \"BMI\" \"Asthma\" \"ICS\" \"LABA\" ...\n  .. ..- attr(*, \"term.labels\")= chr [1:9] \"BMI\" \"Asthma\" \"ICS\" \"LABA\" ...\n  .. ..- attr(*, \"order\")= int [1:9] 1 1 1 1 1 1 1 1 1\n  .. ..- attr(*, \"intercept\")= int 1\n  .. ..- attr(*, \"response\")= int 1\n  .. ..- attr(*, \".Environment\")=&lt;environment: R_GlobalEnv&gt; \n  .. ..- attr(*, \"predvars\")= language list(cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP), BMI, Asthma, ICS, LABA,      Gender, Age_months, Height_cm, Weight_Kg, Group)\n  .. ..- attr(*, \"dataClasses\")= Named chr [1:10] \"nmatrix.4\" \"numeric\" \"character\" \"character\" ...\n  .. .. ..- attr(*, \"names\")= chr [1:10] \"cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP)\" \"BMI\" \"Asthma\" \"ICS\" ...\n $ method      : chr \"REML\"\n $ fitted      : num [1:205, 1:2] 112 110 111 113 113 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:205] \"2\" \"3\" \"5\" \"6\" ...\n  .. ..$ : chr [1:2] \"fixed\" \"Subject_ID\"\n $ residuals   : num [1:205, 1:2] -9.09 -3.37 13.18 -4.1 4.14 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:205] \"2\" \"3\" \"5\" \"6\" ...\n  .. ..$ : chr [1:2] \"fixed\" \"Subject_ID\"\n  ..- attr(*, \"std\")= num [1:205] 11 11 11 11 11 ...\n $ fixDF       :List of 2\n  ..$ X    : Named num [1:10] 111 111 84 111 111 84 111 111 111 84\n  .. ..- attr(*, \"names\")= chr [1:10] \"(Intercept)\" \"BMI\" \"AsthmaYes\" \"ICSYes\" ...\n  ..$ terms: Named num [1:10] 111 111 84 111 111 84 111 111 111 84\n  .. ..- attr(*, \"names\")= chr [1:10] \"(Intercept)\" \"BMI\" \"Asthma\" \"ICS\" ...\n  ..- attr(*, \"assign\")=List of 10\n  .. ..$ (Intercept): int 1\n  .. ..$ BMI        : int 2\n  .. ..$ Asthma     : int 3\n  .. ..$ ICS        : int 4\n  .. ..$ LABA       : int 5\n  .. ..$ Gender     : int 6\n  .. ..$ Age_months : int 7\n  .. ..$ Height_cm  : int 8\n  .. ..$ Weight_Kg  : int 9\n  .. ..$ Group      : int 10\n  ..- attr(*, \"varFixFact\")= num [1:10, 1:10] -1.95 -10.45 -3.1 -1.14 -0.55 ...\n $ na.action   : NULL\n $ data        :'data.frame':   205 obs. of  16 variables:\n  ..$ Group             : Factor w/ 2 levels \"C-Asthma\",\"C-SCD\": 2 2 2 2 2 2 2 2 2 2 ...\n  ..$ Subject_ID        : Factor w/ 90 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 2 3 3 4 5 6 6 7 ...\n  ..$ Observation_number: Factor w/ 6 levels \"1\",\"2\",\"3\",\"4\",..: 2 3 1 1 2 2 1 1 2 1 ...\n  ..$ Hydroxyurea       : chr [1:205] \"Yes\" \"Yes\" \"No\" \"Yes\" ...\n  ..$ Asthma            : chr [1:205] \"Yes\" \"Yes\" \"No\" \"Yes\" ...\n  ..$ ICS               : chr [1:205] \"Yes\" \"Yes\" \"No\" \"No\" ...\n  ..$ LABA              : chr [1:205] \"No\" \"Yes\" \"No\" \"No\" ...\n  ..$ Gender            : chr [1:205] \"male\" \"male\" \"female\" \"male\" ...\n  ..$ Age_months        : num [1:205] 193 198 198 178 186 ...\n  ..$ Height_cm         : num [1:205] 163 164 154 158 164 ...\n  ..$ Weight_Kg         : num [1:205] 62.3 63.1 65.7 51.9 56.7 ...\n  ..$ BMI               : num [1:205] 23.5 23.6 24.6 20.8 20.9 ...\n  ..$ R5Hz_PP           : num [1:205] 103 107 124 109 117 146 136 96 123 117 ...\n  ..$ R20Hz_PP          : num [1:205] 98 98 117 86 105 117 97 109 115 117 ...\n  ..$ X5Hz_PP           : num [1:205] 111 174 98 115 107 195 140 111 164 92 ...\n  ..$ Fres_PP           : num [1:205] 169 159 135 148 159 175 176 104 109 152 ...\n  ..- attr(*, \"na.action\")= 'omit' Named int [1:14] 1 4 8 13 18 21 44 46 50 52 ...\n  .. ..- attr(*, \"names\")= chr [1:14] \"1\" \"4\" \"8\" \"13\" ...\n - attr(*, \"class\")= chr \"lme\"\n\n\nCode\naic_lme_imputed_final &lt;- AIC(model_lme_imputed_final)\n\ncat(sprintf(\"AIC for lme model: %f\\n\", aic_lme_imputed_final))\n\n\nAIC for lme model: 1801.597804\n\n\nCode\n# Extract residuals\nresiduals_imputed &lt;- resid(model_lme_imputed_final)\n\n# Residuals vs Fitted Values Plot\nggplot(data = data.frame(Fitted = fitted(model_lme_imputed_final), Residuals = residuals_imputed), aes(x = Fitted, y = Residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, color = \"red\") +\n  labs(x = \"Fitted Values\", y = \"Residuals\", title = \"Figure 18. Residuals vs. Fitted Values\")\n\n\n\n\n\nCode\n# Histogram of Residuals\nggplot(data = data.frame(Residuals = residuals_imputed), aes(x = Residuals)) +\n  geom_histogram(binwidth = 1, fill = \"blue\", color = \"black\") +\n  labs(title = \"Figure 19. Histogram of Residuals\")\n\n\n\n\n\nCode\n# Q-Q Plot of Residuals\nqqPlot(residuals_imputed, main = \"Figure 20. Q-Q Plot of Residuals\")\n\n\n\n\n\n17 29 \n39 72 \n\n\nCode\n# Shapiro-Wilk Test for Normality of Residuals\nshapiro_test_results &lt;- shapiro.test(residuals_imputed)\nprint(shapiro_test_results)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals_imputed\nW = 0.98676, p-value = 0.0529\n\n\n{.lightbox}\nThe AIC was calculated as 1801.60, an improvement on the initial model but not on the less complex imputed model, as shown in Figure 21. The AIC penalizes model complexity to avoid overfitting, suggesting that the added effects of Group and Observation_number may not be sufficiently increasing model accuracy compared to complexity. However, these effects may still be relevant given the research goal of the project despite the slight increase in AIC, and thus will be left in the final model.\n\n\nCode\n# Model names\nmodel_names &lt;- c(\"1. LME Model\", \"2. LME Imputed Model\", \"3. LME Imputed Final Model\")\n\n# Combining into a dataframe\naic_review &lt;- data.frame(\n  Model = model_names,\n  AIC = c(aic_lme, aic_lme_imputed, aic_lme_imputed_final)\n)\n\naic_review$Model &lt;- as.factor(aic_review$Model)\naic_review$AIC &lt;- round(aic_review$AIC, 2)\n\n# Check the structure\nstr(aic_review)\n\n\n'data.frame':   3 obs. of  2 variables:\n $ Model: Factor w/ 3 levels \"1. LME Model\",..: 1 2 3\n $ AIC  : num  1899 1791 1802\n\n\nCode\nggplot(aic_review, aes(x = Model, y = AIC, fill = Model)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  theme_minimal() +\n  labs(title = \"Figure 21. AIC Values for Different Models\",\n       x = \"Model\",\n       y = \"AIC Value\") +\n  geom_text(aes(label = AIC), vjust = -0.3, size = 3.5) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  coord_flip()\n\n\n\n\n\nThe Shapiro-Wilk test was conducted on the residuals to formally test for normality.\n\\(H_o\\): the residuals are normally distributed.\n\\(H_a\\): the residuals are not normally distributed.\n\\(\\alpha\\) = 0.05\nIn this case, P = 0.0529. P &gt;0.05, so we failed to reject the null hypothesis, suggesting that the residuals were normally distributed after threshold imputation. This final model also satisfies the assumptions of LMMs.\n\n\n3.3.4 Predictions\n\n\nCode\n# Sctter plot of predicted and actuals on y axis and most important category on x axis \n# and split into groups \n\nset.seed(43)\n\n\nlme_resids = residuals(model_lme)\nlme_imputed_resids = residuals(model_lme_imputed)\nlme_imputed_final_resids = residuals(model_lme_imputed_final)\n\n\n\n\nlme_mse = mean(lme_resids^2)\nlme_mae = mean(abs(lme_resids))\n\nlme_imputed_mse = mean(lme_imputed_resids^2)\nlme_imputed_mae = mean(abs(lme_imputed_resids))\n\nlme_imputed_final_mse = mean(lme_imputed_final_resids^2)\nlme_imputed_final_mae = mean(abs(lme_imputed_final_resids))\n\n\nmse_review &lt;- data.frame(\n  Model = model_names,\n  MSE = c(lme_mse, lme_imputed_mse, lme_imputed_final_mse)\n)\n\n\nmse_review$MSE &lt;- round(mse_review$MSE, digits = 2)\n\nmae_review &lt;- data.frame(\n  Model = model_names,\n  MAE = c(lme_mae, lme_imputed_mae, lme_imputed_final_mae)\n)\n\nmae_review$MAE &lt;- round(mae_review$MAE, digits = 2)\n\n\nMSE and MAE\nMean Squared Error (MSE) and Mean Absolute Error (MAE) are metrics used to asses the performance of a model. MSE is the mean of the individual residuals squared and MAE is the mean of the individual absolute value of the residuals. As shown in figures 22 and 23, the imputed final model out performs the other two models by a significant margin. It is important to note that MSE is impacted more by larger errors or outliers because it squares the residuals\n\n\nCode\nggplot(mse_review, aes(x = Model, y = MSE, fill = Model)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  theme_minimal() +\n  labs(title = \"Figure 22. MSE Values for Different Models\",\n       x = \"Model\",\n       y = \"MSE Value\") +\n  geom_text(aes(label = MSE), vjust = -0.3, size = 3.5) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  coord_flip()\n\n\n\n\n\n\n\nCode\nggplot(mae_review, aes(x = Model, y = MAE, fill = Model)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  theme_minimal() +\n  labs(title = \"Figure 23. MAE Values for Different Models\",\n       x = \"Model\",\n       y = \"MAE Value\") +\n  geom_text(aes(label = MAE), vjust = -0.3, size = 3.5) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  coord_flip()\n\n\n\n\n\nSample Predictions vs Actual\nThe bar graph below compares the actual R5Hz_PP to predicted R5Hz_PP (as a measure of airway resistance and reactance) for 10 random subjects. The difference in the bars for each subject is the residual error. The small residual error present for each subject suggests that the model is accurate at predicting R5Hz_PP as a measure of airway resistance and reactance.\n\n\nCode\nlme_imputed_final_predictions = predict(model_lme_imputed_final)\nlme_imputed_fina_preds_actuals = data.frame(cbind(lme_imputed_final_predictions, x_clean_imputed$R5Hz_PP))\n\ncolnames(lme_imputed_fina_preds_actuals) &lt;- c(\"Predicted_R5Hz_PP\", \"Actual_R5Hz_PP\" )\n\nset.seed(42)\n\nsample_indices &lt;- sample(nrow(x_clean_imputed), 10)\nsample_pred_actuals = lme_imputed_fina_preds_actuals[sample_indices, ]\nsample_pred_actuals$row &lt;-1:10\n\n\nsample_pred_actuals_melt &lt;- melt(sample_pred_actuals, id.vars = \"row\")\n\n\nggplot(sample_pred_actuals_melt, aes(x = factor(row), y = value, fill = variable)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(x = \"Observation\", y = \"R5Hz_PP\", fill = \"\") +\n  theme_minimal() +\n  theme(legend.position = \"top\") +\n  ggtitle(\"Figure 24. Sample Comparison of Predicted and Actual Values\")"
  },
  {
    "objectID": "report.html#model-comparisons-and-assessment",
    "href": "report.html#model-comparisons-and-assessment",
    "title": "Report",
    "section": "3.4 Model Comparisons and Assessment",
    "text": "3.4 Model Comparisons and Assessment"
  },
  {
    "objectID": "report.html#simulation-possibly",
    "href": "report.html#simulation-possibly",
    "title": "Report",
    "section": "3.5 Simulation (POSSIBLY)",
    "text": "3.5 Simulation (POSSIBLY)"
  },
  {
    "objectID": "literature.html#multimodel-inference-in-ecology-and-evolution-challenges-and-solutionsnih.gov",
    "href": "literature.html#multimodel-inference-in-ecology-and-evolution-challenges-and-solutionsnih.gov",
    "title": "Literature",
    "section": "Multimodel inference in ecology and evolution: challenges and solutions(nih.gov)",
    "text": "Multimodel inference in ecology and evolution: challenges and solutions(nih.gov)\nWhat is the goal of the paper?\nThe goal of the paper is to highlight obstacles when model averaging and using information theoretic framework and their potential solutions if they exist\nWhy is it important?\nA large number of ecologists and biologists are analyzing data with the Information theoretic framework rather than the traditional hypothesis testing. Modeling averaging becomes increasingly difficult with Linear Mixed models due to the fixed and random effects.\nHow is it solved? – methods\nThe research suggests that researchers define appropriate inputs and predictor variables and to handle collinearity with extreme care especially when dealing with the random effects of LMMs.The paper then goes on to propose strategies on model averaging and definition top model sets.\nResults/limitations, if any.\nAs the paper mentions, it is NOT an exhaustive survival of the potential problems of applying model averaging under an IT framework. Some problems still exist like determining which IT criteria to use when comparing models with random factors."
  },
  {
    "objectID": "literature.html#a-protocol-for-conducting-and-presenting-results-of-regression-type-analyses",
    "href": "literature.html#a-protocol-for-conducting-and-presenting-results-of-regression-type-analyses",
    "title": "Literature",
    "section": "A protocol for conducting and presenting results of regression-type analyses",
    "text": "A protocol for conducting and presenting results of regression-type analyses\nWhat is the goal of the paper?\nThe goal of the paper is to streamline analysis by giving the reader a 10 step protocol. It helps fellow researchers select models, justify assumptions, and validate models.\nWhy is it important?\nThis paper is great for researchers new to Linear Mixed models and are looking to use its advantages on a dataset. The protocol is extremely straightforward. Linear mixed models offer more in depth analysis and it is important that all researchers know it to further the field of ecology.\nHow is it solved? – methods\nThe paper has 10 steps with very concrete examples that include sample datasets, visualizations, and results. The reader has something tangible and can directly apply what they learned to another dataset.\nResults/limitations, if any\nThe paper is limited by showing sample results and shows no empirical data. It identifies potential pitfalls like overdispersion of fitted models but offers no real solution"
  },
  {
    "objectID": "literature.html#multimodel-inference-in-ecology-and-evolution-challenges-and-solutionsnih.gov-1",
    "href": "literature.html#multimodel-inference-in-ecology-and-evolution-challenges-and-solutionsnih.gov-1",
    "title": "Literature",
    "section": "Multimodel inference in ecology and evolution: challenges and solutions(nih.gov)",
    "text": "Multimodel inference in ecology and evolution: challenges and solutions(nih.gov)\nWhat is the goal of the paper?\nThe goal of the paper is to highlight obstacles when model averaging and using information theoretic framework and their potential solutions if they exist\nWhy is it important?\nA large number of ecologists and biologists are analyzing data with the Information theoretic framework rather than the traditional hypothesis testing. Modeling averaging becomes increasingly difficult with Linear Mixed models due to the fixed and random effects.\nHow is it solved? – methods\nThe research suggests that researchers define appropriate inputs and predictor variables and to handle collinearity with extreme care especially when dealing with the random effects of LMMs.The paper then goes on to propose strategies on model averaging and definition top model sets.\nResults/limitations, if any.\nAs the paper mentions, it is NOT an exhaustive survival of the potential problems of applying model averaging under an IT framework. Some problems still exist like determining which IT criteria to use when comparing models with random factors."
  },
  {
    "objectID": "literature.html#using-generalized-linear-mixed-models-to-evaluate-inconsistency-within-a-network-meta-analysis",
    "href": "literature.html#using-generalized-linear-mixed-models-to-evaluate-inconsistency-within-a-network-meta-analysis",
    "title": "Literature",
    "section": "Using Generalized Linear Mixed Models to Evaluate Inconsistency within a Network Meta-Analysis",
    "text": "Using Generalized Linear Mixed Models to Evaluate Inconsistency within a Network Meta-Analysis\nWhat is the goal of the paper?\nThe goal of the paper is to demonstrate how generalized linear mixed models (GLMMs) can evaluate inconsistency within network meta-analyses, improving upon traditional models by using an arm-based approach for more accurate results.\nWhy is it important?\nThe paper addresses the challenge of inconsistency between direct and indirect evidence in network meta-analysis, which can compromise the validity of conclusions, offering a more reliable framework for analysis.\nHow is it solved? – Methods\nThe authors propose an arm-based GLMM approach, which allows for flexible modeling of different outcome variables and shows improved accuracy over contrast-based methods, especially when event rates are low.\nResults/limitations, if any.\nThe arm-based model provided more accurate evaluations of design inconsistency and treatment effects compared to traditional contrast-based approaches, highlighting its utility in complex analyses involving many treatments and designs."
  },
  {
    "objectID": "literature.html#generalized-linear-mixed-model-glmm-trees-a-flexible-decision-tree-method-for-multilevel-and-longitudinal-data",
    "href": "literature.html#generalized-linear-mixed-model-glmm-trees-a-flexible-decision-tree-method-for-multilevel-and-longitudinal-data",
    "title": "Literature",
    "section": "Generalized linear mixed-model (GLMM) trees: A flexible decision-tree method for multilevel and longitudinal data",
    "text": "Generalized linear mixed-model (GLMM) trees: A flexible decision-tree method for multilevel and longitudinal data\nWhat is the goal of the paper?\nThe goal of the paper is to introduce GLMM trees, a method combining generalized linear mixed models (GLMMs) with decision trees for analyzing multilevel and longitudinal data, offering a novel approach to clinical prediction problems.\nWhy is it important?\nGLMM trees provide an interpretable and flexible method that can handle complex data structures, improving upon traditional models by simplifying the analysis and enhancing the understanding of data patterns.\nHow is it solved? – Methods\nThe paper employs GLMM trees to analyze a large dataset from UK mental health services, comparing its performance with traditional GLMMs and random forests to demonstrate its predictive accuracy and efficiency.\nResults/limitations, if any.\nThe method achieves similar predictive accuracy to traditional GLMMs and random forests but with fewer variables, showcasing its potential to streamline clinical decision-making."
  },
  {
    "objectID": "literature.html#multilevel-analysis-quantifies-variation-in-the-experimental-effect-while-optimizing-power-and-preventing-false-positives",
    "href": "literature.html#multilevel-analysis-quantifies-variation-in-the-experimental-effect-while-optimizing-power-and-preventing-false-positives",
    "title": "Literature",
    "section": "Multilevel analysis quantifies variation in the experimental effect while optimizing power and preventing false positives",
    "text": "Multilevel analysis quantifies variation in the experimental effect while optimizing power and preventing false positives\nWhat is the goal of the paper?\nThe goal of this is to show how to handle nested data in neuroscience. Oftentimes data will be collected from the same sample with different experimental conditions. The paper states that this often goes over look in neuroscience\nWhy is it important?\nNot only are several assumptions violated but experiential effects could be miscalculated leading to representing incorrect results.\nHow is it solved? – methods\nThe paper does two simulation studies to show the significance of using the appropriate significant method. Design A had cluster data that may have random effects for just the intercept.. Design B had cluster data that may have random effects in both the intercepts and experiment effect. Both cases resulted in an increase in false positive rates.\nResults/limitations, if any.\nThis data is simulated and only within the context of neuroscience data. It would be beneficial to see these results to a real world dataset"
  },
  {
    "objectID": "report.html#assumptions",
    "href": "report.html#assumptions",
    "title": "Report",
    "section": "2.2 Assumptions",
    "text": "2.2 Assumptions\nAlthough more flexible than other methods such as ANOVA, there are several assumptions for LMMs:\n\nThe relationship between the predictors and response variable is assumed to be linear, within each level of random effects.\nRandom effects (u) are assumed to follow a normal distribution with mean zero and variance-covariance matrix G.\n\\(\\gamma \\sim N(0,G)\\)\nResidual errors (ϵ ) are assumed to follow a normal distribution with mean zero and variance-covariance matrix R.\n\\(\\epsilon \\sim N(0,R)\\)\nRandom effects (u) and residual errors (ϵ ) are assumed to be independent.\nHomoscedasticity is assumed for the residuals across all levels of the independent variables.\n\nThere are several techniques that can be utilized to overcome violations in the LMM assumptions, including variable transformation (to achieve linearity or normality), using robust variance estimates, modifying the structure of random and fixed effects, and employing non-parametric methods or generalized linear mixed models (GLMMs) (Galecki 2014)."
  },
  {
    "objectID": "report.html#implementation-in-r",
    "href": "report.html#implementation-in-r",
    "title": "Report",
    "section": "2.4 Implementation in R",
    "text": "2.4 Implementation in R\nThe implementation begins with importing the dataset into R from a file containing longitudinal retrospective data on the impact of BMI on IOS estimates of airway resistance and reactance in children with sickle cell disease (C-SCD) and African-American children with asthma (C-Asthma). This dataset spans from 2015 to 2020. Data import is executed using the appropriate function, with consideration for specifying file paths and handling header information. Following data importation, preprocessing steps, such as handling missing values and ensuring data integrity, are performed (Galecki 2014).\n\n2.4.1 Analysis Using lme() Function\nAfter preprocessing the data, we proceed with fitting linear mixed-effects models (LMMs) using the lme() function from the nlme package.\nThe analysis employs the lme() function from the nlme package to fit linear mixed-effects models (LMMs). Model formulation involves specifying a model formula that includes both fixed effects (e.g., BMI, diagnosis of asthma, relevant covariates) and random effects (e.g., random intercepts for subjects). The random argument specifies the random effects structure, while the data argument indicates the dataset to be used. The estimation method (method = “REML”) is specified to use restricted maximum likelihood estimation. It is advantageous to use nlme because it offers a user interface for fitting models with structure in the residuals (including forms of heteroscedasticity and autocorrelation) and in the random-effects covariance matrices).\n\n\n2.4.2 Hypothesis Testing\nHypotheses are tested to guide model selection and refinement. For instance, Hypothesis 3.1 [1] assesses whether the variance of random effects is greater than zero, while Hypothesis 3.2 [2] investigates the presence of heterogeneous residual variances across treatment groups. These hypotheses are evaluated using likelihood ratio tests or F-tests, depending on the context.\n\n\n2.4.3 Model Refinement\nBased on the outcomes of hypothesis testing and model diagnostics, the model may be refined by removing non-significant fixed effects or selecting an appropriate covariance structure for the residuals. This iterative process entails fitting alternative models and comparing their fit statistics or testing additional hypotheses.\n\n\n2.4.4. Analysis Using lmer() Function\nAn alternative approach involves utilizing the lmer() function from the lme4 package to fit LMMs. This function follows a similar syntax to lme() but differs in how it handles random effects specification. lme4 offers several benefits compared to nlme, including: more efficient linear algebra tools (with associated performance enhancements), simpler syntax and more efficient implementation for fitting models with crossed random effects, implementation of profile likelihood confidence intervals on random-effects parameters, and the ability to fit GLMMs (Bates et al. 2015). Likelihood ratio tests and model diagnostics are employed to assess model fit and inform model selection (Bates et al. 2015).\n\n\n2.4.5 Final Model Selection\nThe final model is selected based on a synthesis of statistical criteria, including model fit indices, significance of fixed effects, and the adequacy of the model’s assumptions. This selected model is then employed for interpretation and inference concerning the relationships between the predictor variables (e.g., BMI) and the response variable (e.g., IOS measures)."
  },
  {
    "objectID": "report.html#remove.packagesmatrix",
    "href": "report.html#remove.packagesmatrix",
    "title": "Report",
    "section": "remove.packages(“Matrix”)",
    "text": "remove.packages(“Matrix”)"
  },
  {
    "objectID": "report.html#remove.packageslme4",
    "href": "report.html#remove.packageslme4",
    "title": "Report",
    "section": "remove.packages(“lme4”)",
    "text": "remove.packages(“lme4”)"
  },
  {
    "objectID": "report.html#install.packageslme4-type-source",
    "href": "report.html#install.packageslme4-type-source",
    "title": "Report",
    "section": "install.packages(“lme4”, type = “source”)",
    "text": "install.packages(“lme4”, type = “source”)"
  },
  {
    "objectID": "report.html#librarylme4",
    "href": "report.html#librarylme4",
    "title": "Report",
    "section": "library(lme4)",
    "text": "library(lme4)"
  },
  {
    "objectID": "report.html#model-comparison-and-selection",
    "href": "report.html#model-comparison-and-selection",
    "title": "Report",
    "section": "3.4 Model Comparison and Selection",
    "text": "3.4 Model Comparison and Selection\n\n\nCode\n# Compare models based on AIC\naic_lme &lt;- AIC(model_lme)\naic_lmer &lt;- AIC(model_lmer)\n\ncat(sprintf(\"AIC for lme model: %f\\n\", aic_lme))\n\n\nAIC for lme model: 1898.947925\n\n\nCode\ncat(sprintf(\"AIC for lmer model: %f\\n\", aic_lmer))\n\n\nAIC for lmer model: 2517.366883\n\n\nCode\n# Correctly assign final_model based on AIC comparison\nif (aic_lme &lt; aic_lmer) {\n  final_model &lt;- model_lme\n  model_type &lt;- \"lme\"\n} else {\n  final_model &lt;- model_lmer\n  model_type &lt;- \"lmer\"\n}\ncat(sprintf(\"Final model selected: %s\\n\", model_type))\n\n\nFinal model selected: lme\n\n\nCode\n# Since final_model is now correctly assigned, we can call summary on it\nsummary(final_model)\n\n\nLinear mixed-effects model fit by REML\n  Data: x_clean \n       AIC      BIC   logLik\n  1898.948 1935.007 -938.474\n\nRandom effects:\n Formula: ~1 | Subject_ID\n        (Intercept) Residual\nStdDev:    20.45439 19.76738\n\nFixed effects:  cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP) ~ BMI + Asthma + ICS +      LABA + Gender + Age_months + Height_cm + Weight_Kg \n                Value Std.Error  DF   t-value p-value\n(Intercept) 219.89260  86.92601 111  2.529653  0.0128\nBMI          -5.89676   2.67942 111 -2.200761  0.0298\nAsthmaYes    16.70033   7.68459  85  2.173222  0.0325\nICSYes       -4.93414   4.87163 111 -1.012830  0.3133\nLABAYes      -4.35652   6.08228 111 -0.716265  0.4753\nGendermale   -5.68901   5.71803  85 -0.994924  0.3226\nAge_months    0.49796   0.13627 111  3.654088  0.0004\nHeight_cm    -1.04120   0.60384 111 -1.724307  0.0874\nWeight_Kg     1.65587   1.01041 111  1.638804  0.1041\n Correlation: \n           (Intr) BMI    AsthmY ICSYes LABAYs Gndrml Ag_mnt Hght_c\nBMI        -0.927                                                 \nAsthmaYes  -0.135  0.054                                          \nICSYes      0.115 -0.074 -0.378                                   \nLABAYes    -0.011  0.026 -0.055 -0.298                            \nGendermale -0.146  0.146 -0.009 -0.070  0.037                     \nAge_months  0.329 -0.101  0.049 -0.002  0.029  0.146              \nHeight_cm  -0.965  0.830  0.074 -0.110  0.002  0.050 -0.535       \nWeight_Kg   0.938 -0.986 -0.082  0.087 -0.030 -0.122  0.087 -0.852\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.8899152 -0.4840087 -0.1223361  0.4272441  2.5859876 \n\nNumber of Observations: 205\nNumber of Groups: 88 \n\n\nThe Akaike Information Criterion (AIC) for both models was calculated. The AIC is a measure of the relative quality of statistical models for a given set of data. Lower AIC values indicate a model that better fits the data without unnecessary complexity.\nHere, the AIC for lme was 1894.70 while lmer was 2510.44.\nThe model with the lower AIC was selected as the final model (lme) despite performance improvements offered by the lme4 package.\n\n\nCode\n# Residuals\nresiduals_final &lt;- resid(final_model)\n\n# Calculate fitted values and residuals from the final model\nfitted_values &lt;- fitted(final_model)\nresidual_values &lt;- residuals(final_model)\n\n# Create a data frame explicitly for plotting\nplot_data &lt;- data.frame(Fitted = fitted_values, Residuals = residual_values)\n\n# Plotting using ggplot2 for a more flexible and powerful approach\n# Residuals vs Fitted Values\nggplot(plot_data, aes(x = Fitted, y = Residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, color = \"red\") +\n  labs(x = \"Fitted Values\", y = \"Residuals\", title = \"Residuals vs. Fitted Values\")\n\n\n\n\n\n\n\n\n\nResidual plots (Residuals vs. Fitted Values) were created for the lme model to assess the goodness of fit. A horizontal line at y=0 was added as a reference. These plots help in identifying non-linearity, unequal variances, and outliers.\nBased on the residual plot, the model has an ideal random pattern of scattered values with a few possible outliers.\n# Histogram of Residuals\nggplot(plot_data, aes(x = Residuals)) +\ngeom_histogram(binwidth = 1, fill = “blue”, color = “black”) +\nlabs(title = “Histogram of Residuals”)\n# Q-Q Plot\nqqPlot(residuals_final, main = “Q-Q Plot of Residuals”)\n\n\nCode\n# Histogram of Residuals\nggplot(plot_data, aes(x = Residuals)) +\n  geom_histogram(binwidth = 1, fill = \"blue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals\")\n\n\n\n\n\n\n\n\n\nCode\n# Q-Q Plot\nqqPlot(residuals_final, main = \"Q-Q Plot of Residuals\")\n\n\n\n\n\n\n\n\n\n 35  40 \n 95 113 \n\n\nA histogram and a Q-Q (Quantile-Quantile) plot of the residuals were used to check the normality assumption of the residuals. Finally, a QQ plot with a QQ line was produced for a graphical normality check.\nBased on the histogram, the model visually had an ideal bell-shaped curve that resembles the normal distribution. Based on the QQ plot, the model graphically may have had some residuals that were not normally distributed toward the ends.\n\n\nCode\n# Shapiro-Wilk Normality Test\nshapiro_test_results &lt;- shapiro.test(residuals_final)\nprint(shapiro_test_results)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals_final\nW = 0.95883, p-value = 1.163e-05\n\n\nThe Shapiro-Wilk test was conducted on the residuals to formally test for normality.\n\\(H_o\\): the residuals are normally distributed.\n\\(H_a\\): the residuals are not normally distributed.\n\\(\\alpha\\) = 0.05\nIn this case, P = 0.000009375. P &lt; 0.05, so the null hypothesis was rejected, suggesting that the residuals were not normally distributed.\n\n\nCode\n# Copy the original dataset\nx_clean_imputed &lt;- x_clean\n\n# Define a function for Winsorization\nwinsorize &lt;- function(x, lower_percentile = 0.10, upper_percentile = 0.90) {\n  lower_threshold &lt;- quantile(x, lower_percentile)\n  upper_threshold &lt;- quantile(x, upper_percentile)\n  x[x &lt; lower_threshold] &lt;- lower_threshold\n  x[x &gt; upper_threshold] &lt;- upper_threshold\n  \n  return(x)\n}\n\n# Apply imputation across numeric variables in the copied dataset\nnumeric_vars &lt;- names(x_clean_imputed %&gt;% select_if(is.numeric))\nfor (col in numeric_vars) {\n  x_clean_imputed[[col]] &lt;- winsorize(x_clean_imputed[[col]])\n}\n\n\n# Summary after correction\ncat(\"Summary after median imputation:\\n\")\n\n\nSummary after median imputation:\n\n\nCode\nsummary(x_clean_imputed)\n\n\n      Group       Subject_ID  Observation_number Hydroxyurea       \n C-Asthma: 56   40     :  6   1:85               Length:205        \n C-SCD   :149   12     :  5   2:57               Class :character  \n                14     :  5   3:38               Mode  :character  \n                26     :  5   4:19                                 \n                32     :  5   5: 5                                 \n                10     :  4   6: 1                                 \n                (Other):175                                        \n    Asthma              ICS                LABA              Gender         \n Length:205         Length:205         Length:205         Length:205        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   Age_months      Height_cm       Weight_Kg          BMI       \n Min.   : 86.4   Min.   :121.5   Min.   :23.80   Min.   :15.11  \n 1st Qu.:104.0   1st Qu.:131.1   1st Qu.:28.60   1st Qu.:16.08  \n Median :137.0   Median :145.0   Median :38.10   Median :17.80  \n Mean   :140.2   Mean   :145.7   Mean   :41.11   Mean   :18.55  \n 3rd Qu.:176.0   3rd Qu.:160.7   3rd Qu.:52.90   3rd Qu.:20.24  \n Max.   :197.6   Max.   :168.3   Max.   :65.74   Max.   :24.59  \n                                                                \n    R5Hz_PP         R20Hz_PP        X5Hz_PP         Fres_PP     \n Min.   : 67.0   Min.   : 58.0   Min.   : 56.0   Min.   : 94.0  \n 1st Qu.: 81.0   1st Qu.: 69.0   1st Qu.: 81.0   1st Qu.:105.0  \n Median : 99.0   Median : 85.0   Median :110.0   Median :127.0  \n Mean   :101.6   Mean   : 85.2   Mean   :118.2   Mean   :131.1  \n 3rd Qu.:121.0   3rd Qu.: 99.0   3rd Qu.:148.0   3rd Qu.:159.0  \n Max.   :146.0   Max.   :117.0   Max.   :209.2   Max.   :176.0  \n                                                                \n\n\nCode\n# Visualization with ggplot2\n# Plot boxplots for each numeric variable after imputation\nfor (col in numeric_vars) {\n  p &lt;- ggplot(data = x_clean_imputed, aes(x = \"\", y = !!sym(col))) +\n    geom_boxplot(fill = \"skyblue\", color = \"blue\") +\n    labs(title = paste(\"Boxplot of\", col), x = \"\", y = col)\n  print(p)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Modeling with Median Imputed Data\n# Refit the model using the lme function with the cleaned data\nmodel_lme_imputed &lt;- lme(fixed = cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP) ~ BMI + Asthma + ICS + LABA + Gender + Age_months + Height_cm + Weight_Kg,\n                       random = list(Subject_ID = pdIdent(~1)),\n                       data = x_clean_imputed,\n                       method = \"REML\")\n\n# Extract residuals\nresiduals_imputed &lt;- resid(model_lme_imputed)\n\n# Residuals vs Fitted Values Plot\nggplot(data = data.frame(Fitted = fitted(model_lme_imputed), Residuals = residuals_imputed), aes(x = Fitted, y = Residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, color = \"red\") +\n  labs(x = \"Fitted Values\", y = \"Residuals\", title = \"Residuals vs. Fitted Values\")\n\n\n\n\n\n\n\n\n\nCode\n# Histogram of Residuals\nggplot(data = data.frame(Residuals = residuals_imputed), aes(x = Residuals)) +\n  geom_histogram(binwidth = 1, fill = \"blue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals\")\n\n\n\n\n\n\n\n\n\nCode\nqqPlot(residuals_imputed, main = \"Q-Q Plot of Residuals\")\n\n\n\n\n\n\n\n\n\n17 29 \n39 72 \n\n\nCode\n# Q-Q Plot and Shapiro-Wilk Test\nshapiro_test_results &lt;- shapiro.test(residuals_imputed)\nprint(shapiro_test_results)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals_imputed\nW = 0.98664, p-value = 0.05066"
  },
  {
    "objectID": "temp_17mar2024.html",
    "href": "temp_17mar2024.html",
    "title": "R Model",
    "section": "",
    "text": "library(nlme)\nlibrary(lme4)\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'lme4'\n\n\nThe following object is masked from 'package:nlme':\n\n    lmList\n\nlibrary(readr)\nlibrary(Matrix)\nlibrary(nlme)\nlibrary(car)\n\nLoading required package: carData\n\nlibrary(ggplot2)\n\nBMI_IOS_SCD_Asthma <- read_csv(\"BMI_IOS_SCD_Asthma.csv\")\n\nRows: 219 Columns: 16\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): Group, Hydroxyurea, Asthma, ICS, LABA, Gender\ndbl (10): Subject ID, Observation_number, Age (months), Height (cm), Weight ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nbmi_data=BMI_IOS_SCD_Asthma\n\n\nhead(bmi_data)\n\n# A tibble: 6 × 16\n  Group `Subject ID` Observation_number Hydroxyurea Asthma ICS   LABA  Gender\n  <chr>        <dbl>              <dbl> <chr>       <chr>  <chr> <chr> <chr> \n1 C-SCD            1                  1 Yes         Yes    Yes   No    Male  \n2 C-SCD            1                  2 Yes         Yes    Yes   No    Male  \n3 C-SCD            1                  3 Yes         Yes    Yes   Yes   Male  \n4 C-SCD            1                  4 Yes         Yes    Yes   Yes   Male  \n5 C-SCD            2                  1 No          No     No    No    Female\n6 C-SCD            3                  1 Yes         Yes    No    No    Male  \n# ℹ 8 more variables: `Age (months)` <dbl>, `Height (cm)` <dbl>,\n#   `Weight (Kg)` <dbl>, BMI <dbl>, R5Hz_PP <dbl>, R20Hz_PP <dbl>,\n#   X5Hz_PP <dbl>, Fres_PP <dbl>\n\n\n\ncolnames(bmi_data) <- c(\"Group\", \"Subject_ID\", \"Observation_number\", \"Hydroxyurea\", \"Asthma\", \"ICS\", \"LABA\", \"Gender\", \"Age_months\", \"Height_cm\", \"Weight_Kg\", \"BMI\", \"R5Hz_PP\", \"R20Hz_PP\", \"X5Hz_PP\", \"Fres_PP\")\n\n\nbmi_data_clean = na.omit(bmi_data)\n\n\n?lme()\nmodel_lme_clean <- lme(cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP) ~ BMI + Asthma + ICS + LABA + Gender + Age_months + Height_cm + Weight_Kg, \n                 random = list(Subject_ID = pdIdent(~1)), \n                 data = bmi_data_clean, \n                 method = \"REML\")\n\n\nmodel_lmer_clean <- lmer(R5Hz_PP + R20Hz_PP + X5Hz_PP + Fres_PP ~ BMI + Asthma + ICS + LABA + Gender + Age_months + Height_cm + Weight_Kg + (1 | Subject_ID), \n                   data = bmi_data_clean)\n\n\nAIC_lme <- AIC(model_lme_clean)\nAIC_lmer <- AIC(model_lmer_clean)\n\n\ncat(\"AIC for lme model:\", AIC_lme, \"\\n\")\n\nAIC for lme model: 1894.697 \n\ncat(\"AIC for lmer model:\", AIC_lmer, \"\\n\")\n\nAIC for lmer model: 2510.441 \n\nif (AIC_lme < AIC_lmer) {\n  final_model <- model_lme_clean\n  cat(\"Final model selected: lme\\n\")\n} else {\n  final_model <- model_lmer_clean\n  cat(\"Final model selected: lmer\\n\")\n}\n\nFinal model selected: lme\n\nsummary(final_model)\n\nLinear mixed-effects model fit by REML\n  Data: bmi_data_clean \n       AIC      BIC    logLik\n  1894.697 1933.973 -935.3485\n\nRandom effects:\n Formula: ~1 | Subject_ID\n        (Intercept) Residual\nStdDev:    20.66526 19.74809\n\nFixed effects:  cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP) ~ BMI + Asthma + ICS +      LABA + Gender + Age_months + Height_cm + Weight_Kg \n                Value Std.Error  DF   t-value p-value\n(Intercept) 226.43608  88.21974 111  2.566728  0.0116\nBMI          -6.10885   2.71786 111 -2.247668  0.0266\nAsthmaYes    16.07816   7.88142  84  2.040008  0.0445\nICSYes       -4.87575   4.88928 111 -0.997232  0.3208\nLABAYes      -4.87933   6.24234 111 -0.781650  0.4361\nGendermale   -3.47282   7.90991  84 -0.439047  0.6618\nGenderMale   -6.93767   6.46377  84 -1.073316  0.2862\nAge_months    0.51089   0.14105 111  3.621990  0.0004\nHeight_cm    -1.08364   0.61282 111 -1.768289  0.0798\nWeight_Kg     1.71540   1.01913 111  1.683202  0.0951\n Correlation: \n           (Intr) BMI    AsthmY ICSYes LABAYs Gndrml GndrMl Ag_mnt Hght_c\nBMI        -0.928                                                        \nAsthmaYes  -0.160  0.080                                                 \nICSYes      0.124 -0.082 -0.381                                          \nLABAYes    -0.042  0.055 -0.012 -0.303                                   \nGendermale -0.004  0.008 -0.139 -0.006 -0.119                            \nGenderMale -0.195  0.194  0.079 -0.092  0.128  0.336                     \nAge_months  0.352 -0.131  0.001  0.014 -0.023  0.267  0.017              \nHeight_cm  -0.966  0.833  0.100 -0.118  0.033 -0.065  0.110 -0.549       \nWeight_Kg   0.938 -0.986 -0.099  0.093 -0.050 -0.021 -0.152  0.107 -0.853\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.8915211 -0.4632049 -0.1308452  0.4063270  2.5866553 \n\nNumber of Observations: 205\nNumber of Groups: 88 \n\n\n\nresiduals_clean <- resid(model_lme_clean)\n\n\nplot(predict(model_lme_clean), residuals_clean, xlab = \"Fitted Values\", ylab = \"Residuals\")\nabline(h = 0, col = \"red\")  # Add horizontal line at y = 0\ntitle(\"Residuals vs. Fitted Values\")\n\n\n\n\n\nhist(residuals_clean, main = \"Histogram of Residuals\")\n\n\n\n# Q-Q plot\nqqPlot(residuals_clean, main = \"Q-Q Plot of Residuals\")\n\n\n\n\n 35  40 \n 95 113 \n\n\n\nshapiro.test(residuals(model_lme_clean))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(model_lme_clean)\nW = 0.95796, p-value = 9.375e-06\n\nqqnorm(residuals(model_lme_clean))\nqqline(residuals(model_lme_clean))\n\n\n\n\n\nfitted_values <- fitted(model_lme_clean)\nresiduals <- residuals(model_lme_clean)\n\n\nplot(fitted_values, residuals, xlab = \"Fitted values\", ylab = \"Residuals\",\n     main = \"Residuals vs Fitted Values Plot\")\nabline(h = 0, col = \"red\")  # Add a horizontal line at y = 0 for reference"
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html",
    "href": "LMM_presentation/LMM_presentation.html",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "",
    "text": "Data structures & use cases\nFixed v. random effects\nStrengths/weaknesses\nImplementation Methods"
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#linear-algebra",
    "href": "LMM_presentation/LMM_presentation.html#linear-algebra",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "Linear Algebra",
    "text": "Linear Algebra\nLMMs leverage linear algebra and in our case, we are explaining the mathematical concepts for a two-level longitudinal random intercepts model. Index i is used to denote the participant and index t is used to denote the different time points of the observation\n\\[\nY=X\\beta + Zu+ \\epsilon\n\\]\n\nY is the response vector. Shape N x 1 where N is the number of the number of repeated measures\nX is the design matrix for fixed effects. Shape N x p where p is the number of regression coefficients\nβ is the vector of regression coefficients. Shape P x 1\nZ is the design matrix for random effects. Shape N x J where J number of subjects\nu is the vector of random effects. Shape J x 1 vector\nϵ is the vector of residual errors. Shape N x 1 vector"
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#assumptions",
    "href": "LMM_presentation/LMM_presentation.html#assumptions",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "Assumptions",
    "text": "Assumptions\n\nThe relationship between the predictors and response variable is assumed to be linear, within each level of random effects.\nRandom effects (u) are assumed to follow a normal distribution with mean zero and variance-covariance matrix G.\n\\(\\gamma \\sim N(0,G)\\)\nResidual errors (ϵ ) are assumed to follow a normal distribution with mean zero and variance-covariance matrix R.\n\\(\\epsilon \\sim N(0,R)\\)\nRandom effects (u) and residual errors (ϵ ) are assumed to be independent.\nHomoscedasticity is assumed for the residuals across all levels of the independent variables."
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#implementation-in-r",
    "href": "LMM_presentation/LMM_presentation.html#implementation-in-r",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "Implementation in R",
    "text": "Implementation in R\n\nData is loaded from a CSV file using the read.csv function\nFitting Data to LMMs\n\nThe lme() function from the nlme package has parameters to specify random effects structure and estimation method.\nlmer() function from the lme4 package has similar syntax to the lme() function but differs in how it handles random effects specifications\n\nHypothesis Testing\n\nEvaluated using F-tests, Likelihood ratio test, and Shapiro-Wilks tests"
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#the-initial-model",
    "href": "LMM_presentation/LMM_presentation.html#the-initial-model",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "The Initial Model",
    "text": "The Initial Model\nIn this dataset:\n\nMeasures of airway resistance and reactance are the variables of interest: R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP.\nControlled variables are present such as Group, Age, Weight, Height, and other Co-morbidities. These are the fixed effects.\nRandom variability may exist between individual observations which are nested in each subject. These represent the random effects. In the initial model, Subject_ID was treated as the sole random effect.\n[PLACEHOLDER FOR TABLE 5]\n\n\n\n\nEquation 2. The initial LMM."
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#implementation",
    "href": "LMM_presentation/LMM_presentation.html#implementation",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "Implementation",
    "text": "Implementation\n\n#lme()\n\n# Fit models using a tidy and clear approach\nmodel_lme &lt;- lme(\n  fixed = cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP) ~ BMI + Asthma + ICS + LABA + Gender + Age_months + Height_cm + Weight_Kg,\n  random = list(Subject_ID = pdIdent(~1)),\n  data = x_clean,\n  method = \"REML\"\n)\n\n#lmer() \n\nmodel_lmer &lt;- lmer(\n  formula = R5Hz_PP + R20Hz_PP + X5Hz_PP + Fres_PP ~ BMI + Asthma + ICS + LABA + Gender + Age_months + Height_cm + Weight_Kg + (1 | Subject_ID),\n  data = x_clean\n)"
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#evaluation",
    "href": "LMM_presentation/LMM_presentation.html#evaluation",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "Evaluation",
    "text": "Evaluation\n\nAkaike Information Criterion (AIC) - indicator of model fit without unnecessary complexity.\n\nAIC for lme = 1898.95 (selected as initial model)\nAIC for lmer = 2517.37\n\nAssumptions Check - normality.\n\n[PLACEHOLDER FOR FIGURE 11]\n[PLACEHOLDER FOR FIGURE 12]\n[PLACEHOLDER FOR FIGURE 13]\n\nConclusion: the residuals were not normally distributed, so this model does not satisfy the assumptions of LMMs."
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#the-imputed-model",
    "href": "LMM_presentation/LMM_presentation.html#the-imputed-model",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "The Imputed Model",
    "text": "The Imputed Model\n\nUpon further inspection, outliers were present in most variables. To improve model performance, these outliers were imputed using the threshold values.\nConfirmation of outlier removal was completed using boxplots.\nAll metrics were then reevaluated."
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#evaluation-1",
    "href": "LMM_presentation/LMM_presentation.html#evaluation-1",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "Evaluation",
    "text": "Evaluation\n\nAIC for lme = 1790.91 (better!)\n[PLACEHOLDER FOR FIGURE 15]\n[PLACEHOLDER FOR FIGURE 16]\n[PLACEHOLDER FOR FIGURE 17]\nConclusion: the residuals were normally distributed, so this model does satisfies the assumptions of LMMs."
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#the-final-model",
    "href": "LMM_presentation/LMM_presentation.html#the-final-model",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "The Final Model",
    "text": "The Final Model\nThis was a longitudinal study involving multiple observations for each subject over time, and subjects are grouped into two categories (children with sickle cell disease and African-American children with asthma).\nThus, in this final model:\n\nwe modeled Group as a fixed effect since we were interested in the effect of the group itself on the outcome.\nSubject_ID should be a random effect to account for the repeated measures within subjects.\nObservation_number was included as a random slope within Subject_ID (i.e., nested within Subject_ID).\nThe same visualizations and tests were completed to assess the LMM assumptions."
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#the-final-model-1",
    "href": "LMM_presentation/LMM_presentation.html#the-final-model-1",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "The Final Model",
    "text": "The Final Model\n\n\n\nEquation 3. The final LMM."
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#implementation-1",
    "href": "LMM_presentation/LMM_presentation.html#implementation-1",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "Implementation",
    "text": "Implementation\n\nmodel_lme_imputed_final &lt;- lme(fixed = cbind(R5Hz_PP, R20Hz_PP, X5Hz_PP, Fres_PP) ~ BMI + Asthma + ICS + LABA + Gender + Age_months + Height_cm + Weight_Kg + Group,\n                         data = x_clean_imputed,\n                         random = list(Subject_ID = pdIdent(~1 + Observation_number)),\n                         method = \"REML\")"
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#evaluation-2",
    "href": "LMM_presentation/LMM_presentation.html#evaluation-2",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "Evaluation",
    "text": "Evaluation\n\nAIC for lme = 1801.60 (better than initial, but worse than imputed?)\n[PLACEHOLDER FOR FIGURE 21]\n[PLACEHOLDER FOR FIGURE 18]\n[PLACEHOLDER FOR FIGURE 19]\n[PLACEHOLDER FOR FIGURE 20]\nConclusion: the residuals were normally distributed, so this model does satisfies the assumptions of LMMs. The AIC penalizes model complexity to avoid overfitting, suggesting that the added effects of Group and Observation_number may not be sufficiently increasing model accuracy compared to complexity. However, these effects may still be relevant given the research goal of the project despite the slight increase in AIC, and thus will be left in the final model."
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#overview-of-model-evaluations",
    "href": "LMM_presentation/LMM_presentation.html#overview-of-model-evaluations",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "Overview of Model Evaluations",
    "text": "Overview of Model Evaluations\n\nIn our analysis, we compared three Linear Mixed Models: the base model, the model with imputed values, and the final adjusted model, to predict airway resistance and reactance effectively.\nWe focused on Mean Squared Error (MSE) and Mean Absolute Error (MAE) to assess model performance.\n[PLACEHOLDER FOR FIGURE 22]\n[PLACEHOLDER FOR FIGURE 23]\nResults Summary: The final imputed model achieved the lowest MSE and MAE, indicating superior performance over the other models."
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#sample-predictions-vs.-actual-data",
    "href": "LMM_presentation/LMM_presentation.html#sample-predictions-vs.-actual-data",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "Sample Predictions vs. Actual Data",
    "text": "Sample Predictions vs. Actual Data\n\n[PLACEHOLDER FOR FIGURE 24]\nFigure 24 illustrates a side-by-side comparison of the predicted versus actual values for R5Hz_PP, a measure of airway resistance and reactance, for 10 random subjects.\nThe close alignment between predicted and actual values represents a low residual error, confirming the model’s high accuracy in predicting R5Hz_PP."
  },
  {
    "objectID": "LMM_presentation/LMM_presentation.html#conclusion-1",
    "href": "LMM_presentation/LMM_presentation.html#conclusion-1",
    "title": "Inhale, Exhale, Analyze: BMI’s Imprint on Impulse Oscillometry Outcomes",
    "section": "Conclusion",
    "text": "Conclusion\n\nOur analysis demonstrates that linear mixed models are exceptionally versatile and can effectively handle complex datasets with multiple layers of correlation and missing data, incorporating both fixed and random effects seamlessly.\nOur final model accurately predicts airway resistance and reactance given demographic and co-morbidity data, which could aid in better understanding and managing respiratory functions in children with conditions such as Sickle Cell Disease and asthma."
  }
]