---
title: "Individual Literature Reviews"
toc: TRUE
---

# Josh's Literature Review

## [An Introduction to Linear Mixed-Effects Modeling in R - Violet A. Brown, 2021 (uwf.edu)](https://journals-sagepub-com.ezproxy.lib.uwf.edu/doi/full/10.1177/2515245920960351)

**What is the goal of the paper?**

The article aims to introduce the utility of linear mixed-effects models (LMMs) over traditional ANOVA or regression methods, emphasizing their applicability in handling intra-subject differences and their flexibility with missing values and outliers. This was specifically done in R.

**Why is it important?**

LMMs are highlighted for their ability to not assume independence of observations, making them particularly suitable for psychological research where within-subject differences are common.

**How is it solved? – methods**

The article employs a psychology-based dataset to demonstrate the implementation of LMMs using R. It focuses on explaining the concepts of fixed effects and random effects in LMMs, providing the data and code for readers to follow along without delving deeply into the mathematical foundations of LMMs.

**Results/limitations, if any.**

The primary contribution is the detailed walkthrough of LME model syntax in R and interpretation within the context of psychological data. The article suggests that the methods described should be generalizable across various industries, although it is based on a specific psychology dataset.

## [A brief introduction to mixed effects modelling and multi-model inference in ecology - PMC (nih.gov)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5970551/)

**What is the goal of the paper?**

This article aims to demonstrate the application of LMMs and multi-model inference within the field of ecology, focusing on error and model selection using biological data.

**Why is it important?**

The significance of the article lies in its broad overview of LMMs in the context of ecological data, addressing the challenges of error and model selection in ecological research.

**How is it solved? – methods**

The methodology includes a detailed examination of information theory and multi-model inference, applied to example ecological data. The article provides data and code for replication and further exploration.

**Results/limitations, if any.**

While the article offers valuable insights into the use of LMMs in ecology, including data and code for practical application, it primarily serves as an introductory piece, potentially leaving out more advanced aspects of LMMs and multi-model inference.

## [Generalized linear mixed models: a practical guide for ecology and evolution - ScienceDirect](https://www.sciencedirect.com/science/article/abs/pii/S0169534709000196)

What is the goal of the paper?

The goal of this paper is to provide a comprehensive guide on the use and application of Generalized Linear Mixed Models (GLMMs) for ecologists and evolutionary biologists dealing with nonnormal data types, such as counts or proportions, which often do not fit well with classical statistical procedures. The paper aims to clarify the use of GLMMs, given the popularity of these models in recent years.

Why is it important?

The importance of this paper lies in its attempt to introduce GLMMs for biologists, where data often fall outside the scope of methods taught in introductory statistics classes. The paper highlights the limitations of traditional shortcuts like data transformation or ignoring random effects and advocates for GLMMs as a more appropriate statistical approach for nonnormal data with random effects.

How is it solved? – methods

The paper reviews the use and misuse of GLMMs in biology, discusses estimation and inference, and summarizes best-practice data analysis procedures. It emphasizes the need for researchers to match their statistical approaches to their data, rather than forcing data into classical statistical frameworks. The paper discusses various estimation algorithms for fitting GLMMs, including maximum likelihood (ML), pseudo- and penalized quasilikelihood (PQL), Laplace approximations, Gauss-Hermite quadrature (GHQ), and Markov chain Monte Carlo (MCMC) algorithms.

Results/limitations, if any.

While the paper provides a broad overview of GLMM procedures and best practices, it also acknowledges the challenges and controversies in statistical issues such as null hypothesis testing, stepwise regression, and the use of Bayesian statistics. It highlights that GLMMs are powerful tools but can be challenging to use, even for statisticians, due to computational difficulties in estimating parameters, especially for complex models or large numbers of random effects.

## [Frontiers \| Linear mixed-effects models for within-participant psychology experiments: an introductory tutorial and free, graphical user interface (LMMgui) (frontiersin.org)](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00002/full)

What is the goal of the paper?

The goal of this paper is to introduce linear mixed-effects models (LMMs) as a versatile tool for analyzing data from within-participant psychology experiments. It seeks to address the limitations of traditional analysis methods like ANOVA in handling complex data structures, such as those involving repeated measures or nested designs. The paper also introduces LMMgui, a free, graphical user interface designed to facilitate the use of LMMs for researchers using R.

Why is it important?

The importance of this work lies in its potential to enhance the analysis of experimental psychology data by providing a more flexible and robust statistical tool that can handle the complexities of within-participant designs, such as pseudoreplication and missing data. By offering a user-friendly interface for LMM analysis, the paper aims to make advanced statistical methods more accessible to researchers, thereby improving the quality and interpretability of psychological research.

How is it solved? – methods

The paper discusses the theoretical foundation of LMMs, explaining how they can accommodate various data structures and assumptions that are commonly encountered in psychology experiments. It contrasts LMMs with traditional repeated-measures ANOVA, highlighting the advantages of LMMs in terms of their flexibility and fewer stringent assumptions. The introduction of LMMgui is a significant methodological contribution, providing a step-by-step guide on how to use this tool to specify and compare different LMMs for data analysis.

Results/limitations, if any.

While the paper primarily serves as a tutorial and does not present results from a specific study, it effectively demonstrates the application of LMMs through hypothetical examples. These examples illustrate how LMMs can be used to analyze data from within-participant designs, accounting for random effects and complex variance-covariance structures. The paper acknowledges the challenges in interpreting LMM results and the potential for increased Type I error rates in certain conditions, emphasizing the need for careful model comparison and validation.

## [A linear mixed model to estimate COVID-19-induced excess mortality - PubMed (nih.gov)](https://pubmed.ncbi.nlm.nih.gov/34694627/)

What is the goal of the paper?

The goal of this paper is to estimate baseline mortality (mortality under non-pandemic conditions for Belgium and the Netherlands using a linear mixed model (LMM), which can account for both fixed and random effects. If baseline mortality can be modeled, then excess mortality (the measure of the increase in mortality from all causes during a specific time period) can be used to evaluate the impact of COVID-19 on mortality.

Why is it important?

Historically, 5-year weekly averages have been used to determine baseline mortality. However, this excludes year-specific trends in mortality and the effects of historical excess mortality (ex: past influenza breakouts or heat waves). Using a LMM is important because it allows for more accurate modeling that accounts for these factors in the form of random effects.

How is it solved? – methods

The paper proposes a general linear mixed model to model weekly mortality as Y~tj~, with t = 1,…,52 weeks and by year j = 2009…,2020.

The model is then adjusted to: model the cyclic pattern from year to year via random effects of Fourier terms, and reduce the influence of historical excess mortality (as mentioned above) by downweighing the residuals.

Results/limitations, if any.

Several statistics were used to evaluate the model’s forecasting accuracy, including the likelihood ratio test (LRT) and the root mean square error % (RMSE%). The models were fitted to historical mortality year from 2009- week 10 of 2020. The remaining 42 weeks of 2020 were forecasted using the LMM, along with the 5-year average model, and the ground truth data. The models all performed well, so an overall recommendation to include the down-weight procedure for past excess mortality and to include a serial correlation structure were made. The LMM did fit the mortality data better and two years were better predicted compared to the 5-year weekly average models. Many limitations exist, including differences in the reporting of COVID-19 deaths in Belgium and the Netherlands, and across the world. Additionally, it is unclear if the added complexity of LMMs provide a significant benefit over 5-year weekly average models in years besides 2014 and 2016.

## [When a joint model should be preferred over a linear mixed model for analysis of longitudinal health-related quality of life data in cancer clinical trials - PubMed (nih.gov)](https://pubmed.ncbi.nlm.nih.gov/36765307/)

What is the goal of the paper?

The goal of this paper is to address a potential shortcoming of LMMs, which is when data is not missing at random, but instead, data is missing that is dependent on the health-related quality-of-life of the patient (i.e., data is missing because quality-of-life – the outcome - decreased). Viewing missing data like this, a survival model may be more appropriate. Or, as this paper suggests, a joint model (JM) that includes both LMM and survival sub-models.

Why is it important?

This concept is important because clinical trials are frequently employing LMMs to evaluate longitudinal data. Clinical trials involve human subjects, which are known to be more variable compared to benchtop studies. This includes variation in the completeness of patient reported outcome measures (PROMs), especially for longitudinal studies. Many times, this variation is random, and independent of the outcome measure. However, if the outcome measure itself is having an effect on the completeness, then it could represent a major bias limitation of LMMs that should be addressed using the proposed joint models.

How is it solved? – methods

This paper first introduces the LMM that is traditional in longitudinal clinical studies like this. Then, to account for the fact that observations in quality-of-life scores ends with a dropout event, a joint model is created by linking the LMM to a survival model with shared parameters.

This JM was then evaluated using historical clinical trial data where a standard LMM was utilized, and in several simulation studies where extreme examples of this dependence was introduced.

Results/limitations, if any.

This paper showed that poor quality-of-life scores are associated with drop out. Therefore, LMMs should be avoided when analyzing this data in clinical trials. The LMMs in both the historical studies and in the simulations were overly optimistic in estimating the quality-of-life scores. Specifically, the LMM overestimates the slope governing the prediction trajectory in both treatment and control arms. The LMM is also more optimistic for the control arm than the experimental arm, despite the protective effect of treatment on the quality-of-life score.

# Jacob's Literature Review

## [INTRODUCTION TO LINEAR MIXED MODELS (oarc.ucla.edua)](https://stats.oarc.ucla.edu/other/mult-pkg/introduction-to-linear-mixed-models/#:~:text=Linear%20mixed%20models%20are%20an,or%20patients%20from%20within%20doctors)

**What is the goal of the paper?**

The goal of the paper is to show how linear mixed models can help analyze data sets with non independence. Non independence can happen when data is hierarchical in structure resulting in correlations within groups in the data sets resulting in the violation of the assumption of independence between observations. The example provided has a sample dataset with different patient observations belonging to multiple doctors.

**Why is it important?**

Going on the aforementioned example, data can be averaged on a doctor group level but his would result in less data. And you can not make inferences about an individual patient. You can also do multiple linear models for each doctor but the models themselve have less data resulting in more noise. 

**How is it solved? – methods**

Linear Mixed models find a trade off between both approaches where the random effects are still considered for each doctor but there is still an overall grand or fixed effect.

**Results/limitations, if any.**

There was no dataset or experiment analyzed in this paper. It is just a technical overview. 

## [Linear Mixed Model for Analyzing Longitudinal Data: A Simulation Study of Children Growth Differences (sciencedirect.com)](https://www.sciencedirect.com/science/article/pii/S187705091732121X)

**What is the goal of the paper?**

The goal of the paper is to use Linear Mixed Models to analyze multilevel data of developmental growth rates in children. Different covariance structures were modeled within the LMM to capture correlated data through time. 

**Why is it important?**

Growth curves in children are usually represented as a 2 level data structure. At level 2 is the individual child and at the second level is each individual observation. Traditional linear models are not effective due to the non-independence of the data. 

**How is it solved? – methods**

The simulation study found that the UN covariance performed the best although it suffered from efficiency because of the high number of parameters leaving the ARH(1) as a solid alternative. The data was also not naturally collected but simulated 

**Results/limitations, if any.**

The simulation study found that the UN covariance performed the best although it suffered from efficiency because of the high number of parameters leaving the ARH(1) as a solid alternative. The data was also not naturally collected but simulated 

## [A brief introduction to mixed effects modelling and multi-model inference in ecology (nih.gov)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5970551/pdf/peerj-06-4794.pdf)

**What is the goal of the paper?**

The goal of this paper is to serve as a guide on the end to end to end analysis from formulating a hypothesis to inference to explaining the model parameters as it regards to biological and ecological data. Advantages and disadvantages are discussed with the different options available at different parts of the linear mixed model analysis pipeline

**Why is it important?**

This article is relevant to our group especially, to those unfamiliar with Linear Mix Models like myself. As it regards to biological science, this paper helps the reader avoid common pitfalls when implementing LMMs  

**How is it solved? – methods**

The paper has a play by play on the different stages of LMM analysis with tangible example that include data, code and several graphs. 

**Results/limitations, if any**

There is no study or actual experiment being analyzed by linear mixed models. Although it does have references to plenty of academic research papers 


## [LEVEL (Logical Explanations & Visualizations of Estimates in Linear mixed models): recommendations for reporting multilevel data and analyses](https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-019-0876-8)

**What is the goal of the paper?**

Researchers use LLMs to study hierarchical data and often report them under different names like mixed effects models, multilevel data, contextual analysis and hierarchical studies. There is no standardization across these papers for analyzing hierarchical data which leads to different aspects being reported. The goal of the paper is to make a standardized process for analyzing multilevel data 

**Why is it important?**

This is important so studies across different time periods can be compared more easily.

**How is it solved? – methods**

The paper suggests using the LEVEL (Logical Explanations & Visualizations of Estimates in Linear mixed models) as framework for conducting studies with reporting recommendations

**Results/limitations, if any.**

Lack of flexibility. Sticking to a framework can inhibit creative analysis since you’re always looking at the framework for guidance.

## Estimation and selection in linear mixed models with missing data under compound symmetric structure (nih.gov)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9621253/)

**What is the goal of the paper?**

Missing values occur all the time in real data. Statisticians and scientists use linear mixed models as a way to circumvent this issue. This paper aims to examine the estimation and model selection performance when faced with different rates of missing data. The paper employs two types of missing data. Missing at random and not at random.

**Why is it important?**

Given the frequency of missing data it's important to know the impact it has on the model’s results. It's also important to be able to 

**How is it solved? – methods**

Missingness of data is recorded using an indicator based matrix and then a likelihood based estimator is made to capture the probability of distribution of the observed data given the model parameters. 

**Results/limitations, if any.**

There is adequate model performance when there is a moderate amount of missingness in the data. However, the paper focuses on compound symmetric structures which assumes equal variance among any given pair of observations. 


